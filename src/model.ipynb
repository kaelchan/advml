{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-28 21:18:34\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer():\n",
    "    def __init__(self):\n",
    "        self.info = 'main'\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def start(self, info):\n",
    "        self.info = info\n",
    "        self.start_time = time.time()\n",
    "        self.checkpoint('start', elapsed_on=False)\n",
    "    \n",
    "    def end(self):\n",
    "        self.checkpoint(' end ')\n",
    "        \n",
    "    def checkpoint(self, tag, elapsed_on=True):\n",
    "        if elapsed_on:\n",
    "            elapsed = datetime.timedelta(seconds=round(time.time() - self.start_time))\n",
    "            expanded_info = self.info + ' [time elapsed: %s]' % str(elapsed)\n",
    "        else:\n",
    "            expanded_info = self.info\n",
    "        self.output(tag, info=expanded_info)\n",
    "        \n",
    "    def output(self, tag=' '*5, info=''):\n",
    "        if type(info) != type(''):\n",
    "            info = str(info)\n",
    "        print('[%s] (%s) %s' % (Timer.get_current_time(), tag, info))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_current_time():\n",
    "        return time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "timer = Timer()\n",
    "sub_timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-04-28 21:18:39] (start) Load Data\n"
     ]
    }
   ],
   "source": [
    "timer.start('Load Data')\n",
    "# directory = '../data/split/'\n",
    "# df_train = pd.read_csv(directory + 'train.csv')\n",
    "# df_test_warm = pd.read_csv(directory + 'test_warm.csv')\n",
    "# df_test_cold_user = pd.read_csv(directory + 'test_cold_user.csv')\n",
    "# df_test_cold_item = pd.read_csv(directory + 'test_cold_item.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-04-28 21:18:47] (context) Load Data [time elapsed: 0:00:08]\n"
     ]
    }
   ],
   "source": [
    "directory = '../data/context/'\n",
    "df_event_context = pd.read_csv(directory + 'event_context.csv')\n",
    "df_song_context = pd.read_csv(directory + 'song_context.csv')\n",
    "df_user_context = pd.read_csv(directory + 'user_context.csv')\n",
    "timer.checkpoint('context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user = len(df_user_context.user_id.unique())\n",
    "num_item = len(df_song_context.song_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load target sets\n",
    "# import pickle\n",
    "# with open('../data/split/target_set.pickle', 'rb') as handle:\n",
    "#     target_set = pickle.load(handle)\n",
    "# with open('../data/split/train_target_set.pickle', 'rb') as handle:\n",
    "#     train_target_set = pickle.load(handle)\n",
    "# with open('../data/split/test_warm_target_set.pickle', 'rb') as handle:\n",
    "#     test_warm_target_set = pickle.load(handle)\n",
    "# with open('../data/split/test_cold_user_target_set.pickle', 'rb') as handle:\n",
    "#     test_cold_user_target_set = pickle.load(handle)\n",
    "# with open('../data/split/test_cold_item_target_set.pickle', 'rb') as handle:\n",
    "#     test_cold_item_target_set = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, name):\n",
    "        '''\n",
    "        user_list: list(int), the list of user id's used in the dataset\n",
    "        target_set: list(set), set of target items for each user\n",
    "        item_list: list(numpy array), list of items used in the dataset for each user\n",
    "        '''\n",
    "        self.name = name\n",
    "        self.df = None\n",
    "        self.user_list = None\n",
    "        self.item_list = None\n",
    "        self.target_set = None\n",
    "    \n",
    "    def load(self, filename):\n",
    "        self.df = pd.read_csv(filename)\n",
    "        # prepare user list\n",
    "        self.user_list = self.df['user_id'].unique()\n",
    "        \n",
    "        # prepare item list\n",
    "        self.item_list = [[] for i in range(num_user)]\n",
    "        self.df.apply(\n",
    "            lambda row: self.item_list[row['user_id']].append(row['song_id']),\n",
    "            axis=1\n",
    "        )\n",
    "        self.item_list = list(map(np.array, self.item_list))\n",
    "        \n",
    "        # prepare target set\n",
    "        self.target_set = [set() for i in range(num_user)]\n",
    "        self.df[self.df['target'] == 1].apply(\n",
    "            lambda row: self.target_set[row['user_id']].add(row['song_id']),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "# def load_split(name):\n",
    "#     data = Data(name)\n",
    "#     # load the user ids in the data set\n",
    "#     with open('../data/split/' + name + '_user_list.pickle', 'rb') as handle:\n",
    "#         data.user_list = pickle.load(handle)\n",
    "        \n",
    "#     # load the list(set) for items in the data set with label=1\n",
    "#     with open('../data/split/' + name + '_target_set.pickle', 'rb') as handle:\n",
    "#         data.target_set = pickle.load(handle)\n",
    "        \n",
    "#     # load the list(set) for all items in the data set\n",
    "#     with open('../data/split/' + name + '_item_set.pickle', 'rb') as handle:\n",
    "#         data.item_set = pickle.load(handle)\n",
    "        \n",
    "#     return data\n",
    "\n",
    "def load_split(name):\n",
    "    directory = '../data/split/'\n",
    "    data = Data(name)\n",
    "    data.load(directory + name + '.csv')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-04-28 21:23:39] ( end ) Load Data [time elapsed: 0:05:00]\n"
     ]
    }
   ],
   "source": [
    "# data_train = load_split('train')\n",
    "# data_test_warm = load_split('test_warm')\n",
    "# data_test_cold_user = load_split('test_cold_user')\n",
    "# data_test_cold_item = load_split('test_cold_item')\n",
    "\n",
    "data_train = load_split('train')\n",
    "data_test_warm = load_split('test_warm')\n",
    "data_test_cold_user = load_split('test_cold_user')\n",
    "data_test_cold_item = load_split('test_cold_item')\n",
    "timer.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: MF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Reshape, Lambda\n",
    "from keras.layers.merge import concatenate, dot\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform, RandomNormal, TruncatedNormal, Zeros\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define MF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "REG_LAMBDA = 0\n",
    "EMBED_DIM = 64\n",
    "\n",
    "vocab_size = num_user\n",
    "user_embeddings = Embedding(\n",
    "    input_dim = vocab_size,\n",
    "    output_dim = EMBED_DIM,\n",
    "    embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "    embeddings_regularizer = l2(REG_LAMBDA),\n",
    "    input_length = 1,\n",
    "    name = 'user_embed',\n",
    "    trainable=True)\n",
    "\n",
    "vocab_size = num_item\n",
    "item_embeddings = Embedding(\n",
    "    input_dim = vocab_size,\n",
    "    output_dim = EMBED_DIM,\n",
    "    embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "    embeddings_regularizer=l2(REG_LAMBDA),\n",
    "    input_length=1,\n",
    "    name = 'item_embed',\n",
    "    trainable=True)\n",
    "\n",
    "# embedding of user id\n",
    "uid_input = Input(shape=(1,), dtype='int32')\n",
    "embedded_user = user_embeddings(uid_input)\n",
    "embedded_user = Reshape((EMBED_DIM,))(embedded_user)\n",
    "\n",
    "# embedding of song id\n",
    "iid_input = Input(shape=(1,), dtype='int32')\n",
    "embedded_item = item_embeddings(iid_input)\n",
    "embedded_item = Reshape((EMBED_DIM,))(embedded_item)\n",
    "\n",
    "# dot production of embedded vectors\n",
    "preds = dot([embedded_user, embedded_item], axes=1, name='dot_score')\n",
    "\n",
    "# embedding model\n",
    "user_embed_model = Model(inputs=uid_input, outputs=embedded_user)\n",
    "item_embed_model = Model(inputs=iid_input, outputs=embedded_item)\n",
    "\n",
    "model_MF = Model(inputs=[uid_input, iid_input], outputs=preds)\n",
    "model_MF.compile(\n",
    "    loss=keras.losses.mean_squared_error, \n",
    "    optimizer=RMSprop(lr=1e-3),\n",
    "#     optimizer=SGD(lr=1e-4),\n",
    "    metrics=[keras.metrics.mean_squared_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = '../model/mf/'\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "model_path = model_directory + 'mf_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_model_path = '../model/dropout/model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embed (Embedding)          (None, 1, 64)        1968320     input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "item_embed (Embedding)          (None, 1, 64)        23037824    input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 64)           0           user_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 64)           0           item_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_score (Dot)                 (None, 1)            0           reshape_13[0][0]                 \n",
      "                                                                 reshape_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 25,006,144\n",
      "Trainable params: 25,006,144\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[2018-04-26 01:47:07] (start) train MF model\n",
      "Train on 5776897 samples, validate on 500000 samples\n",
      "Epoch 1/100\n",
      "5776897/5776897 [==============================] - 121s 21us/step - loss: 0.4795 - mean_squared_error: 0.4795 - val_loss: 0.3275 - val_mean_squared_error: 0.3275\n",
      "Epoch 2/100\n",
      "5776897/5776897 [==============================] - 108s 19us/step - loss: 0.2623 - mean_squared_error: 0.2623 - val_loss: 0.2325 - val_mean_squared_error: 0.2325\n",
      "Epoch 3/100\n",
      "5776897/5776897 [==============================] - 107s 19us/step - loss: 0.2208 - mean_squared_error: 0.2208 - val_loss: 0.2171 - val_mean_squared_error: 0.2171\n",
      "Epoch 4/100\n",
      "5776897/5776897 [==============================] - 108s 19us/step - loss: 0.2034 - mean_squared_error: 0.2034 - val_loss: 0.2101 - val_mean_squared_error: 0.2101\n",
      "Epoch 5/100\n",
      "5776897/5776897 [==============================] - 108s 19us/step - loss: 0.1909 - mean_squared_error: 0.1909 - val_loss: 0.2068 - val_mean_squared_error: 0.2068\n",
      "Epoch 6/100\n",
      "5776897/5776897 [==============================] - 107s 19us/step - loss: 0.1803 - mean_squared_error: 0.1803 - val_loss: 0.2051 - val_mean_squared_error: 0.2051\n",
      "Epoch 7/100\n",
      "5776897/5776897 [==============================] - 107s 18us/step - loss: 0.1706 - mean_squared_error: 0.1706 - val_loss: 0.2046 - val_mean_squared_error: 0.2046\n",
      "Epoch 8/100\n",
      "5776897/5776897 [==============================] - 106s 18us/step - loss: 0.1616 - mean_squared_error: 0.1616 - val_loss: 0.2050 - val_mean_squared_error: 0.2050\n",
      "Epoch 9/100\n",
      "5776897/5776897 [==============================] - 107s 18us/step - loss: 0.1533 - mean_squared_error: 0.1533 - val_loss: 0.2061 - val_mean_squared_error: 0.2061\n",
      "Epoch 10/100\n",
      "5776897/5776897 [==============================] - 107s 19us/step - loss: 0.1458 - mean_squared_error: 0.1458 - val_loss: 0.2079 - val_mean_squared_error: 0.2079\n",
      "Epoch 11/100\n",
      "5776897/5776897 [==============================] - 106s 18us/step - loss: 0.1391 - mean_squared_error: 0.1391 - val_loss: 0.2102 - val_mean_squared_error: 0.2102\n",
      "Epoch 12/100\n",
      "5776897/5776897 [==============================] - 107s 18us/step - loss: 0.1332 - mean_squared_error: 0.1332 - val_loss: 0.2126 - val_mean_squared_error: 0.2126\n",
      "[2018-04-26 02:08:49] (training finished) \n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "# early stop if no val loss improvement for 5 epochs\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# save best model\n",
    "model_checkpoint = ModelCheckpoint(model_path, save_best_only=True, \\\n",
    "        save_weights_only=True)\n",
    "\n",
    "model_MF.summary()\n",
    "timer.start('train MF model')\n",
    "hist = model_MF.fit(\n",
    "    x=[data_train.df['user_id'], data_train.df['song_id']],\n",
    "    y=data_train.df['target'],\n",
    "    validation_data=(\n",
    "        [data_test_warm.df['user_id'], data_test_warm.df['song_id']],\n",
    "        data_test_warm.df['target']\n",
    "    ),\n",
    "    epochs=100,\n",
    "    batch_size=16*1024,\n",
    "    shuffle=True,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "model_MF.load_weights(model_path) # load the best model\n",
    "timer.output('training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def top_k(score_list, k):\n",
    "#     ind = np.argpartition(score_list, -k)[-k:]\n",
    "#     top_k_ind = list(reversed(ind[np.argsort(score_list[ind])]))\n",
    "#     return top_k_ind\n",
    "\n",
    "def single_top_k(score_list, k):\n",
    "    ind = np.argpartition(score_list, -k)[-k:]\n",
    "    top_k_ind = list(reversed(ind[np.argsort(score_list[ind])]))\n",
    "    return np.array(top_k_ind)\n",
    "\n",
    "# try to implement a two-dimensional top_k\n",
    "def two_dim_top_k(a, k):\n",
    "    return np.array([single_top_k(row, k) for row in a])\n",
    "\n",
    "def top_k(a, k):\n",
    "    if len(a.shape) == 1:\n",
    "        return single_top_k(a, k)\n",
    "    elif len(a.shape) == 2:\n",
    "        return two_dim_top_k(a, k)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model_MF.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 64)\n",
      "[[ 0.09333662 -0.01201833 -0.05492443  0.10049061]\n",
      " [ 0.01422359  0.01635728 -0.01554208 -0.03497285]]\n",
      "[ 0.09333661 -0.01201834 -0.05492445  0.10049061]\n"
     ]
    }
   ],
   "source": [
    "user = 1\n",
    "item_list = np.array([1,2,3,4])\n",
    "v_user = user_embed_model.predict(np.array([1, 2]))\n",
    "v_item = item_embed_model.predict(item_list)\n",
    "\n",
    "print(v_user.shape)\n",
    "\n",
    "_x = v_user @ v_item.T\n",
    "print(_x)\n",
    "\n",
    "print(model_MF.predict([\n",
    "    np.repeat(user, len(item_list)),\n",
    "    item_list\n",
    "]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 19\n"
     ]
    }
   ],
   "source": [
    "print(len(data_test_warm.item_list[1]), len(data_test_warm.target_set[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recall at k\n",
    "sess = tf.Session()\n",
    "v_user_all = user_embed_model.predict(np.arange(num_user))\n",
    "v_item_all = item_embed_model.predict(np.arange(num_item))\n",
    "    \n",
    "def __recall(klist, target, recommend_list):\n",
    "    den = len(target) # denominator\n",
    "    recall_value = 0.0\n",
    "    recall_list = []\n",
    "    for k in klist:\n",
    "        if den < k:\n",
    "            recall_value = 1.0\n",
    "        if recall_value == 1.0: # if it's already 1.0, it should be 1.0 after\n",
    "            recall_list.append(recall_value)\n",
    "            continue\n",
    "        recommend_set = set(recommend_list[:k])\n",
    "        num = len(target & recommend_set)\n",
    "        recall_value = float(num) / float(den)\n",
    "        recall_list.append(recall_value)\n",
    "    return recall_list\n",
    "\n",
    "\n",
    "def recall_mf(model, klist, data):\n",
    "    '''\n",
    "    :param klist: the list of k's in recall@k, e.g. [50, 100, 150, ...]\n",
    "    :param data: data set for evaluation\n",
    "        - user_list\n",
    "        - target_set\n",
    "        - item_set\n",
    "    :return: list(float) for recall at each k, with the same size as klist\n",
    "    '''\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    t1, t2, t3, t4, t5 = 0, 0, 0, 0, 0\n",
    "    for user in data.user_list:\n",
    "        # get the corresponding embedded vectors\n",
    "        v_user = v_user_all[user]\n",
    "        v_item = v_item_all[data.item_list[user]]\n",
    "        \n",
    "        # compute the scores\n",
    "        score_list = v_user @ v_item.T\n",
    "        score_list = score_list.flatten()\n",
    "        # assert len(score_list) == len(data.item_list[user])\n",
    "        \n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        # get the recommended list\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)\n",
    "\n",
    "\n",
    "def recall_random(klist, data):\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    for i, user in enumerate(data.user_list):\n",
    "        # compute the scores\n",
    "        score_list = np.random.uniform(low=0, high=1, size=len(data.item_list[user]))\n",
    "        \n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will be quite slow: each user takes around 4s to run.\n",
    "\n",
    "```\n",
    "score_list = model_MF.predict([\n",
    "    np.repeat(user, len(item_list)),\n",
    "    item_list\n",
    "]).flatten()\n",
    "```\n",
    "\n",
    "**It's because fetching embeddings are slow.** So get the embedding first and use matrix multiplication!\n",
    "\n",
    "After modification, it will still take > 30 mintues (I don't know how long...)\n",
    "\n",
    "### Note!!\n",
    "\n",
    "It's **far more** better to get more from the model at one time rather than calling the model multiple times!\n",
    "\n",
    "The difference between warm and cold is due to the difference in denominator (maybe), so don't compare them with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-04-28 21:23:55] (start) evaluation\n",
      "train\n",
      "[ 0.28405043  0.31350356  0.33461488  0.35292757  0.37250314  0.39203479\n",
      "  0.41084978  0.43105112  0.45112623  0.47041923]\n",
      "[ 0.31114333  0.35040459  0.38176863  0.41004362  0.43711575  0.46288058\n",
      "  0.48721552  0.51096305  0.53371918  0.55523986] \n",
      "\n",
      "test warm\n",
      "[ 0.2025216   0.42456947  0.60538507  0.73497791  0.81995803  0.87823651\n",
      "  0.91583225  0.94101354  0.95784207  0.96861368]\n",
      "[ 0.26750232  0.49173467  0.65854236  0.77200428  0.84624367  0.89548443\n",
      "  0.92770755  0.94943105  0.96372148  0.97313665] \n",
      "\n",
      "test cold user\n",
      "[ 0.54598543  0.67477053  0.75767214  0.81713271  0.86121977  0.8946784\n",
      "  0.92053654  0.94107487  0.95609088  0.96701488]\n",
      "[ 0.54603787  0.67667078  0.75895311  0.81788323  0.8618485   0.89507481\n",
      "  0.92072056  0.94114917  0.95592356  0.96690828] \n",
      "\n",
      "test cold item\n",
      "[ 0.50686612  0.66498714  0.75214242  0.80956632  0.84814032  0.87657266\n",
      "  0.8972806   0.91288526  0.92512048  0.93596406]\n",
      "[ 0.5093784   0.66603463  0.75262869  0.80965487  0.84824089  0.87682556\n",
      "  0.89752886  0.91310884  0.92520717  0.93597828] \n",
      "\n",
      "[2018-04-28 21:24:05] ( end ) evaluation [time elapsed: 0:00:09]\n"
     ]
    }
   ],
   "source": [
    "sub_timer.start('evaluation')\n",
    "klist = list(range(5, 51, 5))\n",
    "print('train')\n",
    "print(recall_random(klist, data_train))\n",
    "print(recall_mf(model_MF, klist, data_train), '\\n')\n",
    "\n",
    "print('test warm')\n",
    "print(recall_random(klist, data_test_warm))\n",
    "print(recall_mf(model_MF, klist, data_test_warm), '\\n')\n",
    "\n",
    "print('test cold user')\n",
    "print(recall_random(klist, data_test_cold_user))\n",
    "print(recall_mf(model_MF, klist, data_test_cold_user), '\\n')\n",
    "\n",
    "print('test cold item')\n",
    "print(recall_random(klist, data_test_cold_item))\n",
    "print(recall_mf(model_MF, klist, data_test_cold_item), '\\n')\n",
    "sub_timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sub_timer.start('evaluation')\n",
    "# klist = list(range(50, 501, 50))\n",
    "# test_user_list = df_test_warm.user_id.unique()\n",
    "# print(recall_mf(model_MF, klist, test_warm_target_set, test_user_list))\n",
    "# sub_timer.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Dropout Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Unnamed: 0', 'user_id'}, set())"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_CATEGORICAL = [\n",
    "    'city', 'gender', 'registered_via', 'registration_year', \n",
    "    'registration_month', 'registration_day', 'expiration_year', \n",
    "    'expiration_month', 'expiration_day']\n",
    "user_NUMERICAL = ['age', 'weird_age', 'validate_days']\n",
    "set(df_user_context.columns) - (set(user_CATEGORICAL).union(set(user_NUMERICAL))), \\\n",
    "set(user_CATEGORICAL).intersection(set(user_NUMERICAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Unnamed: 0', 'song_id'}, set())"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_CATEGORICAL = [\n",
    "    'artist_name', 'composer', 'genre_ids', 'language', \n",
    "    'lyricist', 'song_year']\n",
    "item_NUMERICAL = [\n",
    "    'song_length', 'genre_count', 'lyricist_count',\n",
    "    'composer_count', 'artist_count', 'is_featured',\n",
    "    'artist_composer', 'artist_composer_lyricist', \n",
    "    'song_lang_boolean', 'smaller_song']\n",
    "set(df_song_context.columns) - (set(item_CATEGORICAL).union(set(item_NUMERICAL))), \\\n",
    "set(item_CATEGORICAL).intersection(set(item_NUMERICAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cold(x, recall_at):\n",
    "    embedding_prod_cold = tf.matual(x[0], x[1], transpose_b = True, name='pred_all_items')\n",
    "    _, eval_preds_cold = tf.nn.top_k(embedding_prod_cold, k=recall_at[-1], sorted=True, name='topK_net_cold')\n",
    "    return eval_preds_cold\n",
    "\n",
    "def evaluate_warm(x, recall_at):\n",
    "    embedding_prod_cold = tf.matual(x[0], x[1], transpose_b = True)\n",
    "    embedding_prod_warm = tf.sparse_add(embedding_prod_cold, x[2])\n",
    "    _, eval_preds_warm = tf.nn.top_k(embedding_prod_warm, k=recall_at[-1], sorted=True, name='topK_net_warm')\n",
    "    return eval_preds_warm\n",
    "\n",
    "def prediction(x):\n",
    "    return tf.matmul(x[0], x[1], transpose_b=True)\n",
    "\n",
    "def topk_vals(x, num_candidates):\n",
    "    tf_topk_vals, _ = tf.nn.top_k(x, k=num_candidates, sorted=True)\n",
    "    return tf.reshape(tf_topk_vals, [-1], name='select_y_vals')\n",
    "\n",
    "def topk_inds(x, num_candidates):\n",
    "    _, tf_topk_inds = tf.nn.top_k(x, k=num_candidates, sorted=True)\n",
    "    return tf.reshape(tf_topk_inds, [-1], name='select_y_vals')\n",
    "\n",
    "def random_target(x, num_candidates):\n",
    "    preds_random = tf.gather_nd(x[0], x[1])\n",
    "    return tf.reshape(preds_random, [-1], name='random_y_inds')\n",
    "\n",
    "def latent_topk_cold(x, recall_at):\n",
    "    _, tf_latent_topk_cold = tf.nn.top_k(x, k=recall_at[-1], sorted=True, name='topK_latent_cold')\n",
    "    return tf_latent_topk_cold\n",
    "\n",
    "def latent_topk_warm(x, recall_at):\n",
    "    preds_pref_latent_warm = tf.sparse_add(x[0], x[1])\n",
    "    _, tf_latent_topk_warm = tf.nn.top_k(preds_pref_latent_warm, k=recall_at[-1], sorted=True, name='topK_latent_warm')\n",
    "    return tf_latent_topk_warm\n",
    "\n",
    "def dense_batch_fc_tanh(x, units, scope, do_norm=False):\n",
    "#     w_init = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#     b_init = tf.zeros_initializer()\n",
    "#     h1 = Dense(units, kernel_initializer = w_init, bias_initializer = b_init)(x)\n",
    "    h1 = Dense(units, kernel_initializer = TruncatedNormal(stddev=0.01), bias_initializer = Zeros())(x)\n",
    "    if do_norm:\n",
    "        # h2 = BatchNormalization(momentum = 0.9, center=True, scale=True, training=phase)(h1)\n",
    "        h2 = BatchNormalization(momentum = 0.9, center=True, scale=True)(h1)\n",
    "        return Activation('tanh')(h2)\n",
    "    else:\n",
    "        return Activation('tanh')(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCF:\n",
    "    \"\"\"\n",
    "    main model class implementing DeepCF\n",
    "    also stores states for fast candidate generation\n",
    "\n",
    "    latent_rank_in: rank of preference model input\n",
    "    user_content_rank: rank of user content input\n",
    "    item_content_rank: rank of item content input\n",
    "    model_select: array of number of hidden unit,\n",
    "        i.e. [200,100] indicate two hidden layer with 200 units followed by 100 units\n",
    "    rank_out: rank of latent model output\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_rank_in, model_select, rank_out):\n",
    "        \n",
    "        self.rank_in = latent_rank_in\n",
    "        self.model_select = model_select\n",
    "        self.rank_out = rank_out\n",
    "\n",
    "    def context_model(self, tag, df_context, CATEGORICAL, NUMERICAL):\n",
    "        input_layers = []\n",
    "        embed_layers = []\n",
    "        for col in CATEGORICAL:\n",
    "            input_layer = Input(shape=(1,), name=tag + '_' + col + '_input')\n",
    "            input_layers.append(input_layer)\n",
    "            vocab_size = df_context[col].max() + 1\n",
    "            embed_size = np.power(2, int(np.ceil(np.log2(np.log2(vocab_size)))))\n",
    "            print('[%s] %-20s\\tvocab: %-8d, embed: %-4d' % (tag, col, vocab_size, embed_size))\n",
    "            embed_layer = Embedding(\n",
    "                input_dim = vocab_size,\n",
    "                output_dim = embed_size,\n",
    "                embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "                embeddings_regularizer = l2(1e-4),\n",
    "                input_length = 1,\n",
    "                name = tag + '_' + col+'_embed',\n",
    "                trainable=True)\n",
    "            embed_layer = embed_layer(input_layer)\n",
    "            embed_layer = Reshape((embed_size,))(embed_layer)\n",
    "            embed_layers.append(embed_layer)\n",
    "            \n",
    "        numerical_input = Input(shape=(len(NUMERICAL),), name=tag+'_numerical_input')\n",
    "        input_layers.append(numerical_input)\n",
    "        \n",
    "        preds = concatenate(embed_layers + [numerical_input], name=tag + '_content')\n",
    "#         preds = Dense(64, activation='relu', name=tag + '_content_dense1')(preds)\n",
    "#         preds = Dropout(0.5, name=tag + '_content_dropout')(preds)\n",
    "#         preds = Dense(64, name=tag + '_content_dense1')(preds)\n",
    "        return input_layers, preds\n",
    "            \n",
    "    def build_model(self):\n",
    "        self.Vin = Input(shape=(self.rank_in,), dtype='float32', name='V_in_raw')\n",
    "        self.Uin = Input(shape=(self.rank_in,), dtype='float32', name='U_in_raw')\n",
    "        \n",
    "        self.user_inputs, self.Ucontent = self.context_model(\n",
    "            'user', df_user_context, CATEGORICAL=user_CATEGORICAL, NUMERICAL=user_NUMERICAL)\n",
    "        self.item_inputs, self.Vcontent = self.context_model(\n",
    "            'item', df_song_context, CATEGORICAL=item_CATEGORICAL, NUMERICAL=item_NUMERICAL)\n",
    "        \n",
    "        u_concat = concatenate([self.Uin, self.Ucontent])\n",
    "        v_concat = concatenate([self.Vin, self.Vcontent])\n",
    "        u_last = u_concat\n",
    "        v_last = v_concat\n",
    "        for ihid, hid in enumerate(self.model_select):\n",
    "            u_last = dense_batch_fc_tanh(u_last, hid, 'user_layer_%d' % (ihid + 1), do_norm=True)\n",
    "            v_last = dense_batch_fc_tanh(v_last, hid, 'item_layer_%d' % (ihid + 1), do_norm=True)\n",
    "\n",
    "        self.U_embedding = Dense(\n",
    "            self.rank_out, \n",
    "            kernel_initializer = TruncatedNormal(stddev=0.01),\n",
    "            bias_initializer = Zeros())(u_last)\n",
    "        self.V_embedding = Dense(\n",
    "            self.rank_out, \n",
    "            kernel_initializer = TruncatedNormal(stddev=0.01),\n",
    "            bias_initializer = Zeros())(v_last)\n",
    "        self.preds = dot([self.U_embedding, self.V_embedding], axes=1, name='dot_score')\n",
    "        self.input_layers = [self.Uin, self.Vin] + self.user_inputs + self.item_inputs\n",
    "        \n",
    "        self.user_model = Model(inputs=[self.Uin] + self.user_inputs, outputs=self.U_embedding)\n",
    "        self.item_model = Model(inputs=[self.Vin] + self.item_inputs, outputs=self.V_embedding)\n",
    "        \n",
    "        model = Model(inputs=self.input_layers, outputs=self.preds)\n",
    "        model.compile(optimizer='rmsprop', loss='mean_squared_error')\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user] city                \tvocab: 21      , embed: 8   \n",
      "[user] gender              \tvocab: 3       , embed: 2   \n",
      "[user] registered_via      \tvocab: 5       , embed: 4   \n",
      "[user] registration_year   \tvocab: 14      , embed: 4   \n",
      "[user] registration_month  \tvocab: 12      , embed: 4   \n",
      "[user] registration_day    \tvocab: 31      , embed: 8   \n",
      "[user] expiration_year     \tvocab: 18      , embed: 8   \n",
      "[user] expiration_month    \tvocab: 12      , embed: 4   \n",
      "[user] expiration_day      \tvocab: 31      , embed: 8   \n",
      "[item] artist_name         \tvocab: 40583   , embed: 16  \n",
      "[item] composer            \tvocab: 76064   , embed: 32  \n",
      "[item] genre_ids           \tvocab: 573     , embed: 16  \n",
      "[item] language            \tvocab: 10      , embed: 4   \n",
      "[item] lyricist            \tvocab: 33888   , embed: 16  \n",
      "[item] song_year           \tvocab: 100     , embed: 8   \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_city_input (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_gender_input (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_registered_via_input (Inpu (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_registration_year_input (I (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_registration_month_input ( (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_registration_day_input (In (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_year_input (Inp (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_month_input (In (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_day_input (Inpu (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_artist_name_input (InputLa (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_composer_input (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_genre_ids_input (InputLaye (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_language_input (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_lyricist_input (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_song_year_input (InputLaye (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_city_embed (Embedding)     (None, 1, 8)         168         user_city_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "user_gender_embed (Embedding)   (None, 1, 2)         6           user_gender_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "user_registered_via_embed (Embe (None, 1, 4)         20          user_registered_via_input[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "user_registration_year_embed (E (None, 1, 4)         56          user_registration_year_input[0][0\n",
      "__________________________________________________________________________________________________\n",
      "user_registration_month_embed ( (None, 1, 4)         48          user_registration_month_input[0][\n",
      "__________________________________________________________________________________________________\n",
      "user_registration_day_embed (Em (None, 1, 8)         248         user_registration_day_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_year_embed (Emb (None, 1, 8)         144         user_expiration_year_input[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_month_embed (Em (None, 1, 4)         48          user_expiration_month_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_day_embed (Embe (None, 1, 8)         248         user_expiration_day_input[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "item_artist_name_embed (Embeddi (None, 1, 16)        649328      item_artist_name_input[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "item_composer_embed (Embedding) (None, 1, 32)        2434048     item_composer_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "item_genre_ids_embed (Embedding (None, 1, 16)        9168        item_genre_ids_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "item_language_embed (Embedding) (None, 1, 4)         40          item_language_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "item_lyricist_embed (Embedding) (None, 1, 16)        542208      item_lyricist_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "item_song_year_embed (Embedding (None, 1, 8)         800         item_song_year_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_63 (Reshape)            (None, 8)            0           user_city_embed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_64 (Reshape)            (None, 2)            0           user_gender_embed[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_65 (Reshape)            (None, 4)            0           user_registered_via_embed[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_66 (Reshape)            (None, 4)            0           user_registration_year_embed[0][0\n",
      "__________________________________________________________________________________________________\n",
      "reshape_67 (Reshape)            (None, 4)            0           user_registration_month_embed[0][\n",
      "__________________________________________________________________________________________________\n",
      "reshape_68 (Reshape)            (None, 8)            0           user_registration_day_embed[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_69 (Reshape)            (None, 8)            0           user_expiration_year_embed[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_70 (Reshape)            (None, 4)            0           user_expiration_month_embed[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_71 (Reshape)            (None, 8)            0           user_expiration_day_embed[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "user_numerical_input (InputLaye (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_72 (Reshape)            (None, 16)           0           item_artist_name_embed[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_73 (Reshape)            (None, 32)           0           item_composer_embed[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_74 (Reshape)            (None, 16)           0           item_genre_ids_embed[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_75 (Reshape)            (None, 4)            0           item_language_embed[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_76 (Reshape)            (None, 16)           0           item_lyricist_embed[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_77 (Reshape)            (None, 8)            0           item_song_year_embed[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "item_numerical_input (InputLaye (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "U_in_raw (InputLayer)           (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_content (Concatenate)      (None, 53)           0           reshape_63[0][0]                 \n",
      "                                                                 reshape_64[0][0]                 \n",
      "                                                                 reshape_65[0][0]                 \n",
      "                                                                 reshape_66[0][0]                 \n",
      "                                                                 reshape_67[0][0]                 \n",
      "                                                                 reshape_68[0][0]                 \n",
      "                                                                 reshape_69[0][0]                 \n",
      "                                                                 reshape_70[0][0]                 \n",
      "                                                                 reshape_71[0][0]                 \n",
      "                                                                 user_numerical_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "V_in_raw (InputLayer)           (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_content (Concatenate)      (None, 102)          0           reshape_72[0][0]                 \n",
      "                                                                 reshape_73[0][0]                 \n",
      "                                                                 reshape_74[0][0]                 \n",
      "                                                                 reshape_75[0][0]                 \n",
      "                                                                 reshape_76[0][0]                 \n",
      "                                                                 reshape_77[0][0]                 \n",
      "                                                                 item_numerical_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 117)          0           U_in_raw[0][0]                   \n",
      "                                                                 user_content[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 166)          0           V_in_raw[0][0]                   \n",
      "                                                                 item_content[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 200)          23600       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 200)          33400       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 200)          800         dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 200)          800         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 200)          0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 200)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 100)          20100       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 100)          20100       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 100)          400         dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 100)          400         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 100)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 100)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 100)          10100       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 100)          10100       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_score (Dot)                 (None, 1)            0           dense_23[0][0]                   \n",
      "                                                                 dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,756,378\n",
      "Trainable params: 3,755,178\n",
      "Non-trainable params: 1,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_rank_in = 64\n",
    "model_select = [200, 100]\n",
    "rank_out = 100\n",
    "\n",
    "dropout_net = DeepCF(latent_rank_in, model_select, rank_out)\n",
    "dropout_net.build_model()\n",
    "# dropout_net.build_predictor(klist, n_scores_user)\n",
    "dropout_net.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stopwatch():\n",
    "    def __init__(self, info=''):\n",
    "        self.total = 0\n",
    "        self.info = info\n",
    "    \n",
    "    def clear(self):\n",
    "        self.total = 0\n",
    "    \n",
    "    def tic(self):\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def toc(self):\n",
    "        self.total += time.time() - self.start_time\n",
    "    \n",
    "    def show(self):\n",
    "        print('%.3f seconds \\t %s' % (self.total, self.info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_content(user_list):\n",
    "    return [df_user_context.loc[user_list, col] for col in user_CATEGORICAL] + [df_user_context.loc[user_list, user_NUMERICAL]]\n",
    "        \n",
    "def generate_item_content(item_list):\n",
    "    return [df_song_context.loc[item_list, col] for col in item_CATEGORICAL] + [df_song_context.loc[item_list, item_NUMERICAL]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0.001 seconds \t \n",
      "1:5.945 seconds \t \n",
      "2:0.019 seconds \t \n",
      "3:0.007 seconds \t \n",
      "4:0.002 seconds \t \n",
      "5:0.289 seconds \t \n",
      "6:338.357 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:11.713 seconds \t \n",
      "2:0.050 seconds \t \n",
      "3:0.012 seconds \t \n",
      "4:0.004 seconds \t \n",
      "5:0.563 seconds \t \n",
      "6:688.116 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:17.418 seconds \t \n",
      "2:0.066 seconds \t \n",
      "3:0.012 seconds \t \n",
      "4:0.004 seconds \t \n",
      "5:0.841 seconds \t \n",
      "6:1021.129 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:23.154 seconds \t \n",
      "2:0.081 seconds \t \n",
      "3:0.012 seconds \t \n",
      "4:0.004 seconds \t \n",
      "5:1.061 seconds \t \n",
      "6:1351.857 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:28.836 seconds \t \n",
      "2:0.097 seconds \t \n",
      "3:0.012 seconds \t \n",
      "4:0.004 seconds \t \n",
      "5:1.403 seconds \t \n",
      "6:1682.105 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:34.514 seconds \t \n",
      "2:0.109 seconds \t \n",
      "3:0.018 seconds \t \n",
      "4:0.005 seconds \t \n",
      "5:1.694 seconds \t \n",
      "6:2012.952 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:40.132 seconds \t \n",
      "2:0.109 seconds \t \n",
      "3:0.034 seconds \t \n",
      "4:0.005 seconds \t \n",
      "5:2.059 seconds \t \n",
      "6:2355.258 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:45.876 seconds \t \n",
      "2:0.116 seconds \t \n",
      "3:0.034 seconds \t \n",
      "4:0.005 seconds \t \n",
      "5:2.303 seconds \t \n",
      "6:2686.404 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:51.480 seconds \t \n",
      "2:0.132 seconds \t \n",
      "3:0.034 seconds \t \n",
      "4:0.005 seconds \t \n",
      "5:2.622 seconds \t \n",
      "6:3016.585 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:57.106 seconds \t \n",
      "2:0.149 seconds \t \n",
      "3:0.040 seconds \t \n",
      "4:0.007 seconds \t \n",
      "5:2.906 seconds \t \n",
      "6:3346.325 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:62.744 seconds \t \n",
      "2:0.164 seconds \t \n",
      "3:0.055 seconds \t \n",
      "4:0.007 seconds \t \n",
      "5:3.269 seconds \t \n",
      "6:3681.919 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:68.376 seconds \t \n",
      "2:0.165 seconds \t \n",
      "3:0.071 seconds \t \n",
      "4:0.007 seconds \t \n",
      "5:3.601 seconds \t \n",
      "6:4021.864 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:74.064 seconds \t \n",
      "2:0.197 seconds \t \n",
      "3:0.071 seconds \t \n",
      "4:0.007 seconds \t \n",
      "5:3.852 seconds \t \n",
      "6:4358.124 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:79.644 seconds \t \n",
      "2:0.212 seconds \t \n",
      "3:0.087 seconds \t \n",
      "4:0.007 seconds \t \n",
      "5:4.117 seconds \t \n",
      "6:4688.366 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:85.216 seconds \t \n",
      "2:0.225 seconds \t \n",
      "3:0.093 seconds \t \n",
      "4:0.008 seconds \t \n",
      "5:4.356 seconds \t \n",
      "6:5019.692 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:90.858 seconds \t \n",
      "2:0.238 seconds \t \n",
      "3:0.098 seconds \t \n",
      "4:0.010 seconds \t \n",
      "5:4.565 seconds \t \n",
      "6:5351.623 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:96.482 seconds \t \n",
      "2:0.254 seconds \t \n",
      "3:0.098 seconds \t \n",
      "4:0.010 seconds \t \n",
      "5:4.788 seconds \t \n",
      "6:5683.281 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:102.121 seconds \t \n",
      "2:0.270 seconds \t \n",
      "3:0.098 seconds \t \n",
      "4:0.010 seconds \t \n",
      "5:5.077 seconds \t \n",
      "6:6024.908 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:107.726 seconds \t \n",
      "2:0.299 seconds \t \n",
      "3:0.105 seconds \t \n",
      "4:0.012 seconds \t \n",
      "5:5.472 seconds \t \n",
      "6:6358.455 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:113.303 seconds \t \n",
      "2:0.312 seconds \t \n",
      "3:0.110 seconds \t \n",
      "4:0.013 seconds \t \n",
      "5:5.663 seconds \t \n",
      "6:6684.497 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:118.892 seconds \t \n",
      "2:0.327 seconds \t \n",
      "3:0.110 seconds \t \n",
      "4:0.013 seconds \t \n",
      "5:6.018 seconds \t \n",
      "6:7020.915 seconds \t \n",
      "0:0.001 seconds \t \n",
      "1:124.514 seconds \t \n",
      "2:0.341 seconds \t \n",
      "3:0.115 seconds \t \n",
      "4:0.015 seconds \t \n",
      "5:6.322 seconds \t \n",
      "6:7363.393 seconds \t \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DeepCF' object has no attribute 'save_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-6cefa33c049a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;31m# raise Exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mdropout_model_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../model/dropout/model_{}.h5'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0mdropout_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropout_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DeepCF' object has no attribute 'save_weights'"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "u_pref = v_user_all\n",
    "v_pref = v_item_all\n",
    "_, u_pref_scaled = utils.prep_standardize(u_pref)\n",
    "_, v_pref_scaled = utils.prep_standardize(v_pref)\n",
    "v_pref_expanded = np.vstack([v_pref_scaled, np.zeros_like(v_pref_scaled[0, :])])\n",
    "v_pref_last = v_pref_scaled.shape[0] # the last v_pref_scaled TODO: maybe a all zero?\n",
    "u_pref_expanded = np.vstack([u_pref_scaled, np.zeros_like(u_pref_scaled[0, :])])\n",
    "u_pref_last = u_pref_scaled.shape[0]\n",
    "\n",
    "\n",
    "# configuration\n",
    "user_batch_size = 1000\n",
    "# n_scores_user = 2500\n",
    "n_scores_user = 100\n",
    "\n",
    "data_batch_size = 100\n",
    "max_data_per_step = 2500000\n",
    "num_epoch = 10\n",
    "_lr = 0.005\n",
    "_decay_lr_every = 50\n",
    "_lr_decay = 0.1\n",
    "dropout = 0.5\n",
    "\n",
    "# counting variables\n",
    "n_step = 0\n",
    "n_batch_trained = 0\n",
    "\n",
    "# profiling\n",
    "sw = [Stopwatch() for _ in range(20)]\n",
    "\n",
    "row_index = np.copy(data_train.user_list)\n",
    "for epoch in range(num_epoch):\n",
    "    sw[0].tic()\n",
    "    np.random.shuffle(row_index)\n",
    "    sw[0].toc()\n",
    "    # generate user batches\n",
    "    for b in utils.batch(row_index, user_batch_size):\n",
    "        # n_step: number of batch\n",
    "        n_step += 1\n",
    "        # prep targets\n",
    "        # For each user, n_scores_user of the top (defined by the scores of \n",
    "        # dot product of WMF latent vectors) items are included in the batch\n",
    "        # Besides that, n_scores_user of random items with their scores\n",
    "        # (calculated as above) are also included in the batch, which means\n",
    "        # the ratio is 1:1 for topN and randomN\n",
    "        \n",
    "        # get top_N items for the users\n",
    "        # NOTE: if this takes long time, we can preprocess this part of data and store them\n",
    "        sw[1].tic()\n",
    "        score_matrix = u_pref[b, :] @ v_pref.T\n",
    "        target_users = np.repeat(b, n_scores_user)\n",
    "        target_items = top_k(score_matrix, k = n_scores_user).flatten()\n",
    "        sw[1].toc()\n",
    "        \n",
    "        # get random_N\n",
    "        sw[2].tic()\n",
    "        target_users_rand = np.repeat(np.arange(len(b)), n_scores_user)\n",
    "        target_items_rand = [np.random.choice(v_pref.shape[0], n_scores_user) for _ in b]\n",
    "        target_items_rand = np.array(target_items_rand).flatten()\n",
    "        sw[2].toc()\n",
    "        \n",
    "        sw[3].tic()\n",
    "        target_scores = score_matrix[target_users_rand, target_items]\n",
    "        random_scores = score_matrix[target_users_rand, target_items_rand]\n",
    "        sw[3].toc()\n",
    "\n",
    "        # merge topN and randomN items per user\n",
    "        sw[4].tic()\n",
    "        target_scores = np.append(target_scores, random_scores)\n",
    "        target_items = np.append(target_items, target_items_rand)\n",
    "        target_users = np.append(target_users, target_users)\n",
    "        sw[4].toc()\n",
    "\n",
    "        n_targets = len(target_scores)\n",
    "        perm = np.random.permutation(n_targets)\n",
    "        # n_targets = min(n_targets, max_data_per_step)\n",
    "        data_batch = [(n, min(n + data_batch_size, n_targets)) for n in range(0, n_targets, data_batch_size)]\n",
    "        f_batch = 0\n",
    "        for (start, stop) in data_batch:\n",
    "            sw[5].tic()\n",
    "            batch_perm = perm[start:stop]\n",
    "            batch_users = target_users[batch_perm]\n",
    "            batch_items = target_items[batch_perm]\n",
    "            if dropout != 0:\n",
    "                # dropout * batch_size of users/items are set to pref_last\n",
    "                n_to_drop = int(np.floor(dropout * len(batch_perm)))\n",
    "                perm_user = np.random.permutation(len(batch_perm))[:n_to_drop]\n",
    "                perm_item = np.random.permutation(len(batch_perm))[:n_to_drop]\n",
    "                batch_v_pref = np.copy(batch_items)\n",
    "                batch_u_pref = np.copy(batch_users)\n",
    "                batch_v_pref[perm_user] = v_pref_last\n",
    "                batch_u_pref[perm_item] = u_pref_last\n",
    "            else:\n",
    "                batch_v_pref = batch_items\n",
    "                batch_u_pref = batch_users\n",
    "            sw[5].toc()\n",
    "            \n",
    "            sw[6].tic()\n",
    "            user_content = generate_user_content(batch_users)\n",
    "            item_content = generate_item_content(batch_items)\n",
    "            loss_out = dropout_net.model.train_on_batch(\n",
    "                x = [u_pref_expanded[batch_u_pref, :], v_pref_expanded[batch_v_pref, :]] + user_content + item_content,\n",
    "                y = target_scores[batch_perm], # target\n",
    "            )\n",
    "            sw[6].toc()\n",
    "\n",
    "            f_batch += loss_out\n",
    "            if np.isnan(f_batch):\n",
    "                raise Exception('f is nan')\n",
    "\n",
    "        n_batch_trained += len(data_batch)\n",
    "        # learning rate decay: exponentially\n",
    "        if n_step % _decay_lr_every == 0:\n",
    "            _lr = _lr_decay * _lr\n",
    "            print('decayed lr:' + str(_lr))\n",
    "        for i in range(7):\n",
    "            print(i, end=':')\n",
    "            sw[i].show()\n",
    "        # raise Exception\n",
    "    dropout_model_path = '../model/dropout/model_{}.h5'.format(epoch)\n",
    "    dropout_net.model.save_weights(dropout_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000 seconds \t \n",
      "5.722 seconds \t \n",
      "0.029 seconds \t \n",
      "0.033 seconds \t \n",
      "0.012 seconds \t \n",
      "3.373 seconds \t \n",
      "1300.142 seconds \t \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
