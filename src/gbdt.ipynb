{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-05 20:56:50\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer():\n",
    "    def __init__(self):\n",
    "        self.info = 'main'\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def start(self, info):\n",
    "        self.info = info\n",
    "        self.start_time = time.time()\n",
    "        self.checkpoint('start', elapsed_on=False)\n",
    "    \n",
    "    def end(self):\n",
    "        self.checkpoint(' end ')\n",
    "        \n",
    "    def checkpoint(self, tag, elapsed_on=True):\n",
    "        if elapsed_on:\n",
    "            elapsed = datetime.timedelta(seconds=round(time.time() - self.start_time))\n",
    "            expanded_info = self.info + ' [time elapsed: %s]' % str(elapsed)\n",
    "        else:\n",
    "            expanded_info = self.info\n",
    "        self.output(tag, info=expanded_info)\n",
    "        \n",
    "    def output(self, tag=' '*5, info=''):\n",
    "        if type(info) != type(''):\n",
    "            info = str(info)\n",
    "        print('[%s] (%s) %s' % (Timer.get_current_time(), tag, info))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_current_time():\n",
    "        return time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "timer = Timer()\n",
    "sub_timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-05 21:24:11] (start) Load Data\n"
     ]
    }
   ],
   "source": [
    "timer.start('Load Data')\n",
    "# directory = '../data/split/'\n",
    "# df_train = pd.read_csv(directory + 'train.csv')\n",
    "# df_test_warm = pd.read_csv(directory + 'test_warm.csv')\n",
    "# df_test_cold_user = pd.read_csv(directory + 'test_cold_user.csv')\n",
    "# df_test_cold_item = pd.read_csv(directory + 'test_cold_item.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-05 21:24:18] (context) Load Data [time elapsed: 0:00:07]\n"
     ]
    }
   ],
   "source": [
    "directory = '../data/context/'\n",
    "df_event_context = pd.read_csv(directory + 'event_context.csv')\n",
    "df_song_context = pd.read_csv(directory + 'song_context.csv')\n",
    "df_user_context = pd.read_csv(directory + 'user_context.csv')\n",
    "df_event_context.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_song_context.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_user_context.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "timer.checkpoint('context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30755\n",
      "359966\n"
     ]
    }
   ],
   "source": [
    "num_user = len(df_user_context.user_id.unique())\n",
    "num_item = len(df_song_context.song_id.unique())\n",
    "print (num_user)\n",
    "print (num_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, name):\n",
    "        '''\n",
    "        user_list: list(int), the list of user id's used in the dataset\n",
    "        target_set: list(set), set of target items for each user\n",
    "        item_list: list(numpy array), list of items used in the dataset for each user\n",
    "        '''\n",
    "        self.name = name\n",
    "        self.df = None\n",
    "        self.user_list = None\n",
    "        self.item_list = None\n",
    "        self.target_set = None\n",
    "    \n",
    "    def load(self, filename):\n",
    "        self.df = pd.read_csv(filename)\n",
    "        # prepare user list\n",
    "        self.user_list = self.df['user_id'].unique()\n",
    "        \n",
    "        # prepare item list\n",
    "        self.item_list = [[] for i in range(num_user)]\n",
    "        self.df.apply(\n",
    "            lambda row: self.item_list[row['user_id']].append(row['song_id']),\n",
    "            axis=1\n",
    "        )\n",
    "        self.item_list = list(map(np.array, self.item_list))\n",
    "        \n",
    "        # prepare target set\n",
    "        self.target_set = [set() for i in range(num_user)]\n",
    "        self.df[self.df['target'] == 1].apply(\n",
    "            lambda row: self.target_set[row['user_id']].add(row['song_id']),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "def load_split(name):\n",
    "    directory = '../data/split/'\n",
    "    data = Data(name)\n",
    "    data.load(directory + name + '.csv')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = load_split('train')\n",
    "# data_test_warm = load_split('test_warm')\n",
    "# data_test_cold_user = load_split('test_cold_user')\n",
    "# data_test_cold_item = load_split('test_cold_item')\n",
    "# timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dump the class for more efficient data preparing\n",
    "# import pickle\n",
    "# with open('../data/split/data_train.pickle', 'wb') as handle:\n",
    "#     pickle.dump(data_train, handle)\n",
    "# with open('../data/split/data_test_cold_user.pickle', 'wb') as handle:\n",
    "#     pickle.dump(data_test_cold_user, handle)\n",
    "# with open('../data/split/data_test_cold_item.pickle', 'wb') as handle:\n",
    "#     pickle.dump(data_test_cold_item, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-05 21:24:22] ( end ) Load Data [time elapsed: 0:00:11]\n"
     ]
    }
   ],
   "source": [
    "# load the data class\n",
    "import pickle\n",
    "with open('../data/split/data_train.pickle', 'rb') as handle:\n",
    "    data_train = pickle.load(handle)\n",
    "with open('../data/split/data_test_warm.pickle', 'rb') as handle:\n",
    "    data_test_warm = pickle.load(handle)\n",
    "with open('../data/split/data_test_cold_user.pickle', 'rb') as handle:\n",
    "    data_test_cold_user = pickle.load(handle)\n",
    "with open('../data/split/data_test_cold_item.pickle', 'rb') as handle:\n",
    "    data_test_cold_item = pickle.load(handle)\n",
    "timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data_test_warm.df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data_test_cold_user.df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data_test_cold_item.df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Reshape, Lambda, Multiply\n",
    "from keras.layers.merge import concatenate, dot\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform, RandomNormal, TruncatedNormal, Zeros\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and load the MF model for comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "REG_LAMBDA = 0\n",
    "EMBED_DIM = 64\n",
    "\n",
    "vocab_size = num_user\n",
    "user_embeddings = Embedding(\n",
    "    input_dim = vocab_size,\n",
    "    output_dim = EMBED_DIM,\n",
    "    embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "    embeddings_regularizer = l2(REG_LAMBDA),\n",
    "    input_length = 1,\n",
    "    name = 'user_embed',\n",
    "    trainable=True)\n",
    "\n",
    "vocab_size = num_item\n",
    "item_embeddings = Embedding(\n",
    "    input_dim = vocab_size,\n",
    "    output_dim = EMBED_DIM,\n",
    "    embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "    embeddings_regularizer=l2(REG_LAMBDA),\n",
    "    input_length=1,\n",
    "    name = 'item_embed',\n",
    "    trainable=True)\n",
    "\n",
    "# embedding of user id\n",
    "uid_input = Input(shape=(1,), dtype='int32')\n",
    "embedded_user = user_embeddings(uid_input)\n",
    "embedded_user = Reshape((EMBED_DIM,))(embedded_user)\n",
    "\n",
    "# embedding of song id\n",
    "iid_input = Input(shape=(1,), dtype='int32')\n",
    "embedded_item = item_embeddings(iid_input)\n",
    "embedded_item = Reshape((EMBED_DIM,))(embedded_item)\n",
    "\n",
    "# dot production of embedded vectors\n",
    "preds = dot([embedded_user, embedded_item], axes=1, name='dot_score')\n",
    "\n",
    "# embedding model\n",
    "user_embed_model = Model(inputs=uid_input, outputs=embedded_user)\n",
    "item_embed_model = Model(inputs=iid_input, outputs=embedded_item)\n",
    "\n",
    "model_MF = Model(inputs=[uid_input, iid_input], outputs=preds)\n",
    "model_MF.compile(\n",
    "    loss=keras.losses.mean_squared_error, \n",
    "    optimizer=RMSprop(lr=1e-3),\n",
    "#     optimizer=SGD(lr=1e-4),\n",
    "    metrics=[keras.metrics.mean_squared_error])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = '../model/mf/'\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "model_path = model_directory + 'mf_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model_MF.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_top_k(score_list, k):\n",
    "    ind = np.argpartition(score_list, -k)[-k:]\n",
    "    top_k_ind = list(reversed(ind[np.argsort(score_list[ind])]))\n",
    "    return np.array(top_k_ind)\n",
    "\n",
    "# try to implement a two-dimensional top_k\n",
    "def two_dim_top_k(a, k):\n",
    "    return np.array([single_top_k(row, k) for row in a])\n",
    "\n",
    "def top_k(a, k):\n",
    "    if len(a.shape) == 1:\n",
    "        return single_top_k(a, k)\n",
    "    elif len(a.shape) == 2:\n",
    "        return two_dim_top_k(a, k)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recall at k\n",
    "sess = tf.Session()\n",
    "v_user_all = user_embed_model.predict(np.arange(num_user))\n",
    "v_item_all = item_embed_model.predict(np.arange(num_item))\n",
    "    \n",
    "def __recall(klist, target, recommend_list):\n",
    "    den = len(target) # denominator\n",
    "    recall_value = 0.0\n",
    "    recall_list = []\n",
    "    for k in klist:\n",
    "        if den < k:\n",
    "            recall_value = 1.0\n",
    "        if recall_value == 1.0: # if it's already 1.0, it should be 1.0 after\n",
    "            recall_list.append(recall_value)\n",
    "            continue\n",
    "        recommend_set = set(recommend_list[:k])\n",
    "        num = len(target & recommend_set)\n",
    "        recall_value = float(num) / float(den)\n",
    "        recall_list.append(recall_value)\n",
    "    return recall_list\n",
    "\n",
    "\n",
    "def recall_mf(model, klist, data):\n",
    "    '''\n",
    "    :param klist: the list of k's in recall@k, e.g. [50, 100, 150, ...]\n",
    "    :param data: data set for evaluation\n",
    "        - user_list\n",
    "        - target_set\n",
    "        - item_set\n",
    "    :return: list(float) for recall at each k, with the same size as klist\n",
    "    '''\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    t1, t2, t3, t4, t5 = 0, 0, 0, 0, 0\n",
    "    for user in data.user_list:\n",
    "        # get the corresponding embedded vectors\n",
    "        v_user = v_user_all[user]\n",
    "        v_item = v_item_all[data.item_list[user]]\n",
    "        \n",
    "        # compute the scores\n",
    "        #score_list = v_user @ v_item.T\n",
    "        score_list = np.matmul(v_user, v_item.T)\n",
    "        score_list = score_list.flatten()\n",
    "        # assert len(score_list) == len(data.item_list[user])\n",
    "        \n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        # get the recommended list\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)\n",
    "\n",
    "\n",
    "def recall_random(klist, data):\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    for i, user in enumerate(data.user_list):\n",
    "        # compute the scores\n",
    "        score_list = np.random.uniform(low=0, high=1, size=len(data.item_list[user]))\n",
    "        \n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stopwatch():\n",
    "    def __init__(self, info=''):\n",
    "        self.total = 0\n",
    "        self.info = info\n",
    "    \n",
    "    def clear(self):\n",
    "        self.total = 0\n",
    "    \n",
    "    def tic(self):\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def toc(self):\n",
    "        self.total += time.time() - self.start_time\n",
    "    \n",
    "    def show(self):\n",
    "        print('%.3f seconds \\t %s' % (self.total, self.info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stopwatch():\n",
    "    def __init__(self, info=''):\n",
    "        self.total = 0\n",
    "        self.info = info\n",
    "    \n",
    "    def clear(self):\n",
    "        self.total = 0\n",
    "    \n",
    "    def tic(self):\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def toc(self):\n",
    "        self.total += time.time() - self.start_time\n",
    "    \n",
    "    def show(self):\n",
    "        print('%.3f seconds \\t %s' % (self.total, self.info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'user_id'}, set())"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_CATEGORICAL = [\n",
    "    'city', 'gender', 'registered_via', 'registration_year', \n",
    "    'registration_month', 'registration_day', 'expiration_year', \n",
    "    'expiration_month', 'expiration_day']\n",
    "user_NUMERICAL = ['age', 'weird_age', 'validate_days']\n",
    "set(df_user_context.columns) - (set(user_CATEGORICAL).union(set(user_NUMERICAL))), \\\n",
    "set(user_CATEGORICAL).intersection(set(user_NUMERICAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'song_id'}, set())"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_CATEGORICAL = [\n",
    "    'artist_name', 'composer', 'genre_ids', 'language', \n",
    "    'lyricist', 'song_year']\n",
    "item_NUMERICAL = [\n",
    "    'song_length', 'genre_count', 'lyricist_count',\n",
    "    'composer_count', 'artist_count', 'is_featured',\n",
    "    'artist_composer', 'artist_composer_lyricist', \n",
    "    'song_lang_boolean', 'smaller_song']\n",
    "set(df_song_context.columns) - (set(item_CATEGORICAL).union(set(item_NUMERICAL))), \\\n",
    "set(item_CATEGORICAL).intersection(set(item_NUMERICAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(df):\n",
    "    ret = df.merge(df_user_context, on='user_id', how='left')\n",
    "    ret = ret.merge(df_song_context, on='song_id', how='left')\n",
    "    for col in user_CATEGORICAL + item_CATEGORICAL + ['user_id', 'song_id']:\n",
    "        ret[col] = ret[col].astype('category')\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = merge_df(data_train.df)\n",
    "test_warm = merge_df(data_test_warm.df)\n",
    "test_cold_user = merge_df(data_test_cold_user.df)\n",
    "test_cold_item = merge_df(data_test_cold_item.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(df):\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df['target']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop(columns=['target'])\n",
    "y = train['target']\n",
    "X_trn, X_val, y_trn, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "d_trn = lgb.Dataset(X_trn, y_trn)\n",
    "d_val = lgb.Dataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_train = prepare_lgb_data(train)\n",
    "X_warm, y_warm = separate(test_warm)\n",
    "X_cold_user, y_cold_user = separate(test_cold_user)\n",
    "X_cold_item, y_cold_item = separate(test_cold_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary', # objective is the goal\n",
    "#     'objective': 'mse',\n",
    "    'metric': 'auc',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.3,\n",
    "    'verbose': 0,\n",
    "    'num_leaves': 108,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_seed': 1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'feature_fraction_seed': 1,\n",
    "    'max_bin': 256,\n",
    "    'max_depth': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's auc: 0.622092\n",
      "[10]\tvalid_0's auc: 0.64764\n",
      "[15]\tvalid_0's auc: 0.667652\n",
      "[20]\tvalid_0's auc: 0.679133\n",
      "[25]\tvalid_0's auc: 0.68866\n",
      "[30]\tvalid_0's auc: 0.696314\n",
      "[35]\tvalid_0's auc: 0.702537\n",
      "[40]\tvalid_0's auc: 0.707131\n",
      "[45]\tvalid_0's auc: 0.710982\n",
      "[50]\tvalid_0's auc: 0.713872\n",
      "[55]\tvalid_0's auc: 0.716974\n",
      "[60]\tvalid_0's auc: 0.719603\n",
      "[65]\tvalid_0's auc: 0.722066\n",
      "[70]\tvalid_0's auc: 0.724093\n",
      "[75]\tvalid_0's auc: 0.726662\n",
      "[80]\tvalid_0's auc: 0.728321\n",
      "[85]\tvalid_0's auc: 0.729886\n",
      "[90]\tvalid_0's auc: 0.731445\n",
      "[95]\tvalid_0's auc: 0.732592\n",
      "[100]\tvalid_0's auc: 0.733587\n",
      "[105]\tvalid_0's auc: 0.734664\n",
      "[110]\tvalid_0's auc: 0.735616\n",
      "[115]\tvalid_0's auc: 0.736379\n",
      "[120]\tvalid_0's auc: 0.737133\n",
      "[125]\tvalid_0's auc: 0.737767\n",
      "[130]\tvalid_0's auc: 0.739166\n",
      "[135]\tvalid_0's auc: 0.739898\n",
      "[140]\tvalid_0's auc: 0.740836\n",
      "[145]\tvalid_0's auc: 0.741988\n",
      "[150]\tvalid_0's auc: 0.74252\n",
      "[155]\tvalid_0's auc: 0.742929\n",
      "[160]\tvalid_0's auc: 0.743353\n",
      "[165]\tvalid_0's auc: 0.743702\n",
      "[170]\tvalid_0's auc: 0.744315\n",
      "[175]\tvalid_0's auc: 0.744657\n",
      "[180]\tvalid_0's auc: 0.745126\n",
      "[185]\tvalid_0's auc: 0.745413\n",
      "[190]\tvalid_0's auc: 0.745983\n",
      "[195]\tvalid_0's auc: 0.746387\n",
      "[200]\tvalid_0's auc: 0.747086\n",
      "[205]\tvalid_0's auc: 0.747312\n",
      "[210]\tvalid_0's auc: 0.747535\n",
      "[215]\tvalid_0's auc: 0.747825\n",
      "[220]\tvalid_0's auc: 0.748091\n",
      "[225]\tvalid_0's auc: 0.748463\n",
      "[230]\tvalid_0's auc: 0.748732\n",
      "[235]\tvalid_0's auc: 0.748957\n",
      "[240]\tvalid_0's auc: 0.749172\n",
      "[245]\tvalid_0's auc: 0.74953\n",
      "[250]\tvalid_0's auc: 0.749879\n",
      "[255]\tvalid_0's auc: 0.750635\n",
      "[260]\tvalid_0's auc: 0.750883\n",
      "[265]\tvalid_0's auc: 0.751341\n",
      "[270]\tvalid_0's auc: 0.751963\n",
      "[275]\tvalid_0's auc: 0.752218\n",
      "[280]\tvalid_0's auc: 0.752566\n",
      "[285]\tvalid_0's auc: 0.75276\n",
      "[290]\tvalid_0's auc: 0.753344\n",
      "[295]\tvalid_0's auc: 0.753609\n",
      "[300]\tvalid_0's auc: 0.753814\n",
      "[305]\tvalid_0's auc: 0.754072\n",
      "[310]\tvalid_0's auc: 0.754273\n",
      "[315]\tvalid_0's auc: 0.754451\n",
      "[320]\tvalid_0's auc: 0.754587\n",
      "[325]\tvalid_0's auc: 0.755122\n",
      "[330]\tvalid_0's auc: 0.755329\n",
      "[335]\tvalid_0's auc: 0.755532\n",
      "[340]\tvalid_0's auc: 0.755663\n",
      "[345]\tvalid_0's auc: 0.755996\n",
      "[350]\tvalid_0's auc: 0.756373\n",
      "[355]\tvalid_0's auc: 0.75652\n",
      "[360]\tvalid_0's auc: 0.756765\n",
      "[365]\tvalid_0's auc: 0.75702\n",
      "[370]\tvalid_0's auc: 0.757333\n",
      "[375]\tvalid_0's auc: 0.757449\n",
      "[380]\tvalid_0's auc: 0.75768\n",
      "[385]\tvalid_0's auc: 0.758068\n",
      "[390]\tvalid_0's auc: 0.758793\n",
      "[395]\tvalid_0's auc: 0.758881\n",
      "[400]\tvalid_0's auc: 0.759007\n",
      "[405]\tvalid_0's auc: 0.759155\n",
      "[410]\tvalid_0's auc: 0.759275\n",
      "[415]\tvalid_0's auc: 0.75956\n",
      "[420]\tvalid_0's auc: 0.759803\n",
      "[425]\tvalid_0's auc: 0.760001\n",
      "[430]\tvalid_0's auc: 0.760167\n",
      "[435]\tvalid_0's auc: 0.760254\n",
      "[440]\tvalid_0's auc: 0.760631\n",
      "[445]\tvalid_0's auc: 0.760728\n",
      "[450]\tvalid_0's auc: 0.760781\n",
      "[455]\tvalid_0's auc: 0.761057\n",
      "[460]\tvalid_0's auc: 0.761164\n",
      "[465]\tvalid_0's auc: 0.761235\n",
      "[470]\tvalid_0's auc: 0.76133\n",
      "[475]\tvalid_0's auc: 0.761449\n",
      "[480]\tvalid_0's auc: 0.761541\n",
      "[485]\tvalid_0's auc: 0.761716\n",
      "[490]\tvalid_0's auc: 0.761826\n",
      "[495]\tvalid_0's auc: 0.761893\n",
      "[500]\tvalid_0's auc: 0.761963\n"
     ]
    }
   ],
   "source": [
    "print(params)\n",
    "model_lgb = lgb.train(params, train_set=d_trn,  valid_sets=d_val, num_boost_round=500, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def recall_gbdt(klist, data, X):\n",
    "    df = data.df\n",
    "    df['score'] = model_lgb.predict(X, raw_score=True)\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    for user in data.user_list:\n",
    "        # compute the scores\n",
    "        score_list = np.ravel(df[df['user_id'] == user]['score'])\n",
    "        \n",
    "        # get the recommended list\n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def recall_score_model(klist, data, v_user_all, v_item_all):\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    for user in data.user_list:\n",
    "        # get the corresponding embedded vectors\n",
    "        v_user = v_user_all[user]\n",
    "        v_item = v_item_all[data.item_list[user]]\n",
    "        \n",
    "        # compute the scores\n",
    "        score_list = np.matmul(v_user, v_item.T)\n",
    "        score_list = score_list.flatten()\n",
    "        # assert len(score_list) == len(data.item_list[user])\n",
    "        \n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        # get the recommended list\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-05 22:48:48] (start) evaluation of gbdt\n",
      "{'objective': 'mse', 'metric': 'auc', 'boosting': 'gbdt', 'learning_rate': 0.3, 'verbose': 0, 'num_leaves': 108, 'bagging_fraction': 0.95, 'bagging_freq': 1, 'bagging_seed': 1, 'feature_fraction': 0.9, 'feature_fraction_seed': 1, 'max_bin': 256, 'max_depth': 10}\n",
      "train\n",
      "[ 0.28393633  0.31342538  0.3348515   0.35304667  0.3726993   0.39222678\n",
      "  0.41111398  0.43128242  0.45126038  0.47039166]\n",
      "[ 0.31114333  0.35040459  0.38176863  0.41004362  0.43711575  0.46288058\n",
      "  0.48721552  0.51096305  0.53371918  0.55523986]\n",
      "[ 0.29908512  0.33957839  0.37022252  0.39698448  0.42311439  0.44827857\n",
      "  0.471769    0.49523115  0.5178026   0.53900154]\n",
      "\n",
      "test warm\n",
      "[ 0.20366892  0.42460244  0.60659798  0.73549538  0.82027472  0.87843515\n",
      "  0.91584737  0.94082619  0.95763389  0.96854577]\n",
      "[ 0.26750232  0.49173467  0.65854236  0.77200428  0.84624367  0.89548443\n",
      "  0.92770755  0.94943105  0.96372148  0.97313665]\n",
      "[ 0.22892688  0.4494995   0.6248442   0.7487097   0.82927477  0.88428635\n",
      "  0.92018868  0.94402336  0.96001068  0.97025558]\n",
      "\n",
      "test cold user\n",
      "[ 0.54601601  0.67581673  0.75829212  0.81734291  0.86160848  0.89512693\n",
      "  0.92087487  0.94122467  0.95608641  0.96701825]\n",
      "[ 0.54603787  0.67667078  0.75895311  0.81788323  0.8618485   0.89507481\n",
      "  0.92072056  0.94114917  0.95592356  0.96690828]\n",
      "[ 0.56378242  0.693084    0.77387142  0.83056138  0.87203132  0.90343993\n",
      "  0.92741801  0.94617742  0.95966364  0.96987829]\n",
      "\n",
      "test cold item\n",
      "[ 0.50737597  0.6652899   0.75257783  0.80961974  0.84830561  0.87660254\n",
      "  0.89724088  0.91288386  0.92515865  0.93602083]\n",
      "[ 0.5093784   0.66603463  0.75262869  0.80965487  0.84824089  0.87682556\n",
      "  0.89752886  0.91310884  0.92520717  0.93597828]\n",
      "[ 0.52714215  0.68218559  0.76594463  0.82095864  0.85765761  0.8845045\n",
      "  0.90406862  0.91876374  0.93018159  0.94016677]\n",
      "\n",
      "[2018-05-05 22:57:00] ( end ) evaluation of gbdt [time elapsed: 0:08:12]\n"
     ]
    }
   ],
   "source": [
    "sub_timer.start('evaluation of gbdt')\n",
    "print(params)\n",
    "klist = list(range(5, 51, 5))\n",
    "# print('train')\n",
    "# print(recall_random(klist, data_train))\n",
    "# print(recall_score_model(klist, data_train, v_user_all, v_item_all))\n",
    "# print(recall_gbdt(klist, data_train, X))\n",
    "# print()\n",
    "\n",
    "print('test warm')\n",
    "print(recall_random(klist, data_test_warm))\n",
    "print(recall_score_model(klist, data_test_warm, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_warm, X_warm))\n",
    "print()\n",
    "\n",
    "print('test cold user')\n",
    "print(recall_random(klist, data_test_cold_user))\n",
    "print(recall_score_model(klist, data_test_cold_user, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_cold_user, X_cold_user))\n",
    "print()\n",
    "\n",
    "print('test cold item')\n",
    "print(recall_random(klist, data_test_cold_item))\n",
    "print(recall_score_model(klist, data_test_cold_item, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_cold_item, X_cold_item))\n",
    "print()\n",
    "sub_timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-05 22:21:53] (start) evaluation of gbdt\n",
      "train\n",
      "[ 0.28376551  0.31351217  0.33472762  0.35290057  0.37247065  0.39207905\n",
      "  0.41107759  0.43129761  0.45129646  0.47054151]\n",
      "[ 0.31114333  0.35040459  0.38176863  0.41004362  0.43711575  0.46288058\n",
      "  0.48721552  0.51096305  0.53371918  0.55523986]\n",
      "[ 0.29820165  0.3380293   0.36808844  0.39405887  0.41955349  0.44395652\n",
      "  0.46705401  0.49012433  0.51230534  0.53325818]\n",
      "\n",
      "test warm\n",
      "[ 0.20288517  0.42455798  0.60570106  0.73470763  0.81978877  0.87790244\n",
      "  0.91558135  0.94077069  0.9576234   0.96857412]\n",
      "[ 0.26750232  0.49173467  0.65854236  0.77200428  0.84624367  0.89548443\n",
      "  0.92770755  0.94943105  0.96372148  0.97313665]\n",
      "[ 0.23634062  0.45479177  0.62841269  0.750463    0.83061545  0.8852908\n",
      "  0.92056212  0.94424607  0.96009602  0.97038821]\n",
      "\n",
      "test cold user\n",
      "[ 0.54591386  0.67538501  0.75803218  0.8174759   0.86178933  0.89488659\n",
      "  0.9207422   0.94118112  0.95606108  0.96692304]\n",
      "[ 0.54603787  0.67667078  0.75895311  0.81788323  0.8618485   0.89507481\n",
      "  0.92072056  0.94114917  0.95592356  0.96690828]\n",
      "[ 0.56371795  0.6933783   0.77436189  0.83084736  0.87237157  0.90375936\n",
      "  0.92754859  0.9463917   0.95981859  0.96995137]\n",
      "\n",
      "test cold item\n",
      "[ 0.50718421  0.6653645   0.752355    0.80962994  0.84805707  0.87667191\n",
      "  0.89718312  0.91281028  0.92501592  0.93592013]\n",
      "[ 0.5093784   0.66603463  0.75262869  0.80965487  0.84824089  0.87682556\n",
      "  0.89752886  0.91310884  0.92520717  0.93597828]\n",
      "[ 0.5260037   0.6811007   0.76496021  0.82022664  0.85734649  0.88409721\n",
      "  0.90371152  0.91840362  0.92994906  0.93989959]\n",
      "\n",
      "[2018-05-05 22:30:22] ( end ) evaluation of gbdt [time elapsed: 0:08:29]\n"
     ]
    }
   ],
   "source": [
    "sub_timer.start('evaluation of gbdt')\n",
    "print(params)\n",
    "'''\n",
    "{'objective': 'binary', 'metric': 'auc', 'boosting': 'gbdt', 'learning_rate': 0.3, 'verbose': 0, 'num_leaves': 108, 'bagging_fraction': 0.95, \n",
    "'bagging_freq': 1, 'bagging_seed': 1, 'feature_fraction': 0.9, 'feature_fraction_seed': 1, 'max_bin': 256, 'max_depth': 10}\n",
    "'''\n",
    "klist = list(range(5, 51, 5))\n",
    "print('train')\n",
    "print(recall_random(klist, data_train))\n",
    "print(recall_score_model(klist, data_train, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_train, X))\n",
    "print()\n",
    "\n",
    "print('test warm')\n",
    "print(recall_random(klist, data_test_warm))\n",
    "print(recall_score_model(klist, data_test_warm, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_warm, X_warm))\n",
    "print()\n",
    "\n",
    "print('test cold user')\n",
    "print(recall_random(klist, data_test_cold_user))\n",
    "print(recall_score_model(klist, data_test_cold_user, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_cold_user, X_cold_user))\n",
    "print()\n",
    "\n",
    "print('test cold item')\n",
    "print(recall_random(klist, data_test_cold_item))\n",
    "print(recall_score_model(klist, data_test_cold_item, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_cold_item, X_cold_item))\n",
    "print()\n",
    "sub_timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load previous model\n",
    "# model_path = '../model/dropout/variation1.hf5'\n",
    "# dropout_net.model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archived"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
