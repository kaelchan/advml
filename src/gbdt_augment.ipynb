{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-06 00:19:22\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer():\n",
    "    def __init__(self):\n",
    "        self.info = 'main'\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def start(self, info):\n",
    "        self.info = info\n",
    "        self.start_time = time.time()\n",
    "        self.checkpoint('start', elapsed_on=False)\n",
    "    \n",
    "    def end(self):\n",
    "        self.checkpoint(' end ')\n",
    "        \n",
    "    def checkpoint(self, tag, elapsed_on=True):\n",
    "        if elapsed_on:\n",
    "            elapsed = datetime.timedelta(seconds=round(time.time() - self.start_time))\n",
    "            expanded_info = self.info + ' [time elapsed: %s]' % str(elapsed)\n",
    "        else:\n",
    "            expanded_info = self.info\n",
    "        self.output(tag, info=expanded_info)\n",
    "        \n",
    "    def output(self, tag=' '*5, info=''):\n",
    "        if type(info) != type(''):\n",
    "            info = str(info)\n",
    "        print('[%s] (%s) %s' % (Timer.get_current_time(), tag, info))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_current_time():\n",
    "        return time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "timer = Timer()\n",
    "sub_timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-06 00:19:22] (start) Load Data\n"
     ]
    }
   ],
   "source": [
    "timer.start('Load Data')\n",
    "# directory = '../data/split/'\n",
    "# df_train = pd.read_csv(directory + 'train.csv')\n",
    "# df_test_warm = pd.read_csv(directory + 'test_warm.csv')\n",
    "# df_test_cold_user = pd.read_csv(directory + 'test_cold_user.csv')\n",
    "# df_test_cold_item = pd.read_csv(directory + 'test_cold_item.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-06 00:19:28] (context) Load Data [time elapsed: 0:00:06]\n"
     ]
    }
   ],
   "source": [
    "directory = '../data/context/'\n",
    "df_event_context = pd.read_csv(directory + 'event_context.csv')\n",
    "df_song_context = pd.read_csv(directory + 'song_context.csv')\n",
    "df_user_context = pd.read_csv(directory + 'user_context.csv')\n",
    "df_event_context.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_song_context.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_user_context.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "timer.checkpoint('context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30755\n",
      "359966\n"
     ]
    }
   ],
   "source": [
    "num_user = len(df_user_context.user_id.unique())\n",
    "num_item = len(df_song_context.song_id.unique())\n",
    "print (num_user)\n",
    "print (num_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, name):\n",
    "        '''\n",
    "        user_list: list(int), the list of user id's used in the dataset\n",
    "        target_set: list(set), set of target items for each user\n",
    "        item_list: list(numpy array), list of items used in the dataset for each user\n",
    "        '''\n",
    "        self.name = name\n",
    "        self.df = None\n",
    "        self.user_list = None\n",
    "        self.item_list = None\n",
    "        self.target_set = None\n",
    "    \n",
    "    def load(self, filename):\n",
    "        self.df = pd.read_csv(filename)\n",
    "        # prepare user list\n",
    "        self.user_list = self.df['user_id'].unique()\n",
    "        \n",
    "        # prepare item list\n",
    "        self.item_list = [[] for i in range(num_user)]\n",
    "        self.df.apply(\n",
    "            lambda row: self.item_list[row['user_id']].append(row['song_id']),\n",
    "            axis=1\n",
    "        )\n",
    "        self.item_list = list(map(np.array, self.item_list))\n",
    "        \n",
    "        # prepare target set\n",
    "        self.target_set = [set() for i in range(num_user)]\n",
    "        self.df[self.df['target'] == 1].apply(\n",
    "            lambda row: self.target_set[row['user_id']].add(row['song_id']),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "def load_split(name):\n",
    "    directory = '../data/split/'\n",
    "    data = Data(name)\n",
    "    data.load(directory + name + '.csv')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = load_split('train')\n",
    "# data_test_warm = load_split('test_warm')\n",
    "# data_test_cold_user = load_split('test_cold_user')\n",
    "# data_test_cold_item = load_split('test_cold_item')\n",
    "# timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dump the class for more efficient data preparing\n",
    "# import pickle\n",
    "# with open('../data/split/data_train.pickle', 'wb') as handle:\n",
    "#     pickle.dump(data_train, handle)\n",
    "# with open('../data/split/data_test_cold_user.pickle', 'wb') as handle:\n",
    "#     pickle.dump(data_test_cold_user, handle)\n",
    "# with open('../data/split/data_test_cold_item.pickle', 'wb') as handle:\n",
    "#     pickle.dump(data_test_cold_item, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-06 00:19:32] ( end ) Load Data [time elapsed: 0:00:10]\n"
     ]
    }
   ],
   "source": [
    "# load the data class\n",
    "import pickle\n",
    "with open('../data/split/data_train.pickle', 'rb') as handle:\n",
    "    data_train = pickle.load(handle)\n",
    "with open('../data/split/data_test_warm.pickle', 'rb') as handle:\n",
    "    data_test_warm = pickle.load(handle)\n",
    "with open('../data/split/data_test_cold_user.pickle', 'rb') as handle:\n",
    "    data_test_cold_user = pickle.load(handle)\n",
    "with open('../data/split/data_test_cold_item.pickle', 'rb') as handle:\n",
    "    data_test_cold_item = pickle.load(handle)\n",
    "timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data_test_warm.df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data_test_cold_user.df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data_test_cold_item.df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Reshape, Lambda, Multiply\n",
    "from keras.layers.merge import concatenate, dot\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform, RandomNormal, TruncatedNormal, Zeros\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and load the MF model for comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "REG_LAMBDA = 0\n",
    "EMBED_DIM = 64\n",
    "\n",
    "vocab_size = num_user\n",
    "user_embeddings = Embedding(\n",
    "    input_dim = vocab_size,\n",
    "    output_dim = EMBED_DIM,\n",
    "    embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "    embeddings_regularizer = l2(REG_LAMBDA),\n",
    "    input_length = 1,\n",
    "    name = 'user_embed',\n",
    "    trainable=True)\n",
    "\n",
    "vocab_size = num_item\n",
    "item_embeddings = Embedding(\n",
    "    input_dim = vocab_size,\n",
    "    output_dim = EMBED_DIM,\n",
    "    embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "    embeddings_regularizer=l2(REG_LAMBDA),\n",
    "    input_length=1,\n",
    "    name = 'item_embed',\n",
    "    trainable=True)\n",
    "\n",
    "# embedding of user id\n",
    "uid_input = Input(shape=(1,), dtype='int32')\n",
    "embedded_user = user_embeddings(uid_input)\n",
    "embedded_user = Reshape((EMBED_DIM,))(embedded_user)\n",
    "\n",
    "# embedding of song id\n",
    "iid_input = Input(shape=(1,), dtype='int32')\n",
    "embedded_item = item_embeddings(iid_input)\n",
    "embedded_item = Reshape((EMBED_DIM,))(embedded_item)\n",
    "\n",
    "# dot production of embedded vectors\n",
    "preds = dot([embedded_user, embedded_item], axes=1, name='dot_score')\n",
    "\n",
    "# embedding model\n",
    "user_embed_model = Model(inputs=uid_input, outputs=embedded_user)\n",
    "item_embed_model = Model(inputs=iid_input, outputs=embedded_item)\n",
    "\n",
    "model_MF = Model(inputs=[uid_input, iid_input], outputs=preds)\n",
    "model_MF.compile(\n",
    "    loss=keras.losses.mean_squared_error, \n",
    "    optimizer=RMSprop(lr=1e-3),\n",
    "#     optimizer=SGD(lr=1e-4),\n",
    "    metrics=[keras.metrics.mean_squared_error])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = '../model/mf/'\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "model_path = model_directory + 'mf_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model_MF.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_top_k(score_list, k):\n",
    "    ind = np.argpartition(score_list, -k)[-k:]\n",
    "    top_k_ind = list(reversed(ind[np.argsort(score_list[ind])]))\n",
    "    return np.array(top_k_ind)\n",
    "\n",
    "# try to implement a two-dimensional top_k\n",
    "def two_dim_top_k(a, k):\n",
    "    return np.array([single_top_k(row, k) for row in a])\n",
    "\n",
    "def top_k(a, k):\n",
    "    if len(a.shape) == 1:\n",
    "        return single_top_k(a, k)\n",
    "    elif len(a.shape) == 2:\n",
    "        return two_dim_top_k(a, k)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recall at k\n",
    "sess = tf.Session()\n",
    "v_user_all = user_embed_model.predict(np.arange(num_user))\n",
    "v_item_all = item_embed_model.predict(np.arange(num_item))\n",
    "    \n",
    "def __recall(klist, target, recommend_list):\n",
    "    den = len(target) # denominator\n",
    "    recall_value = 0.0\n",
    "    recall_list = []\n",
    "    for k in klist:\n",
    "        if den < k:\n",
    "            recall_value = 1.0\n",
    "        if recall_value == 1.0: # if it's already 1.0, it should be 1.0 after\n",
    "            recall_list.append(recall_value)\n",
    "            continue\n",
    "        recommend_set = set(recommend_list[:k])\n",
    "        num = len(target & recommend_set)\n",
    "        recall_value = float(num) / float(den)\n",
    "        recall_list.append(recall_value)\n",
    "    return recall_list\n",
    "\n",
    "\n",
    "def recall_mf(model, klist, data):\n",
    "    '''\n",
    "    :param klist: the list of k's in recall@k, e.g. [50, 100, 150, ...]\n",
    "    :param data: data set for evaluation\n",
    "        - user_list\n",
    "        - target_set\n",
    "        - item_set\n",
    "    :return: list(float) for recall at each k, with the same size as klist\n",
    "    '''\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    t1, t2, t3, t4, t5 = 0, 0, 0, 0, 0\n",
    "    for user in data.user_list:\n",
    "        # get the corresponding embedded vectors\n",
    "        v_user = v_user_all[user]\n",
    "        v_item = v_item_all[data.item_list[user]]\n",
    "        \n",
    "        # compute the scores\n",
    "        #score_list = v_user @ v_item.T\n",
    "        score_list = np.matmul(v_user, v_item.T)\n",
    "        score_list = score_list.flatten()\n",
    "        # assert len(score_list) == len(data.item_list[user])\n",
    "        \n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        # get the recommended list\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)\n",
    "\n",
    "\n",
    "def recall_random(klist, data):\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    for i, user in enumerate(data.user_list):\n",
    "        # compute the scores\n",
    "        score_list = np.random.uniform(low=0, high=1, size=len(data.item_list[user]))\n",
    "        \n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT Model\n",
    "\n",
    "with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stopwatch():\n",
    "    def __init__(self, info=''):\n",
    "        self.total = 0\n",
    "        self.info = info\n",
    "    \n",
    "    def clear(self):\n",
    "        self.total = 0\n",
    "    \n",
    "    def tic(self):\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def toc(self):\n",
    "        self.total += time.time() - self.start_time\n",
    "    \n",
    "    def show(self):\n",
    "        print('%.3f seconds \\t %s' % (self.total, self.info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stopwatch():\n",
    "    def __init__(self, info=''):\n",
    "        self.total = 0\n",
    "        self.info = info\n",
    "    \n",
    "    def clear(self):\n",
    "        self.total = 0\n",
    "    \n",
    "    def tic(self):\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def toc(self):\n",
    "        self.total += time.time() - self.start_time\n",
    "    \n",
    "    def show(self):\n",
    "        print('%.3f seconds \\t %s' % (self.total, self.info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'user_id'}, set())"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_CATEGORICAL = [\n",
    "    'city', 'gender', 'registered_via', 'registration_year', \n",
    "    'registration_month', 'registration_day', 'expiration_year', \n",
    "    'expiration_month', 'expiration_day']\n",
    "user_NUMERICAL = ['age', 'weird_age', 'validate_days']\n",
    "set(df_user_context.columns) - (set(user_CATEGORICAL).union(set(user_NUMERICAL))), \\\n",
    "set(user_CATEGORICAL).intersection(set(user_NUMERICAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'song_id'}, set())"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_CATEGORICAL = [\n",
    "    'artist_name', 'composer', 'genre_ids', 'language', \n",
    "    'lyricist', 'song_year']\n",
    "item_NUMERICAL = [\n",
    "    'song_length', 'genre_count', 'lyricist_count',\n",
    "    'composer_count', 'artist_count', 'is_featured',\n",
    "    'artist_composer', 'artist_composer_lyricist', \n",
    "    'song_lang_boolean', 'smaller_song']\n",
    "set(df_song_context.columns) - (set(item_CATEGORICAL).union(set(item_NUMERICAL))), \\\n",
    "set(item_CATEGORICAL).intersection(set(item_NUMERICAL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train = data_train.df\n",
    "aug_train = aug_train.loc[np.repeat(aug_train.index.values, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "aug_train['idx'] = np.arange(len(aug_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train = aug_train.merge(df_user_context, on='user_id', how='left')\n",
    "aug_train = aug_train.merge(df_song_context, on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>target</th>\n",
       "      <th>idx</th>\n",
       "      <th>city</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>weird_age</th>\n",
       "      <th>validate_days</th>\n",
       "      <th>...</th>\n",
       "      <th>song_year</th>\n",
       "      <th>artist_count</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>lyricist_count</th>\n",
       "      <th>composer_count</th>\n",
       "      <th>is_featured</th>\n",
       "      <th>artist_composer</th>\n",
       "      <th>artist_composer_lyricist</th>\n",
       "      <th>song_lang_boolean</th>\n",
       "      <th>smaller_song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13362</td>\n",
       "      <td>232041</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.823033</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.891258</td>\n",
       "      <td>0.799278</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.203198</td>\n",
       "      <td>-0.168081</td>\n",
       "      <td>-0.425957</td>\n",
       "      <td>0.591896</td>\n",
       "      <td>-0.059925</td>\n",
       "      <td>-0.234705</td>\n",
       "      <td>-0.131524</td>\n",
       "      <td>-0.294843</td>\n",
       "      <td>0.828389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13362</td>\n",
       "      <td>232041</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.823033</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.891258</td>\n",
       "      <td>0.799278</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.203198</td>\n",
       "      <td>-0.168081</td>\n",
       "      <td>-0.425957</td>\n",
       "      <td>0.591896</td>\n",
       "      <td>-0.059925</td>\n",
       "      <td>-0.234705</td>\n",
       "      <td>-0.131524</td>\n",
       "      <td>-0.294843</td>\n",
       "      <td>0.828389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13362</td>\n",
       "      <td>232041</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.823033</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.891258</td>\n",
       "      <td>0.799278</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.203198</td>\n",
       "      <td>-0.168081</td>\n",
       "      <td>-0.425957</td>\n",
       "      <td>0.591896</td>\n",
       "      <td>-0.059925</td>\n",
       "      <td>-0.234705</td>\n",
       "      <td>-0.131524</td>\n",
       "      <td>-0.294843</td>\n",
       "      <td>0.828389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13362</td>\n",
       "      <td>232041</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.823033</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.891258</td>\n",
       "      <td>0.799278</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.203198</td>\n",
       "      <td>-0.168081</td>\n",
       "      <td>-0.425957</td>\n",
       "      <td>0.591896</td>\n",
       "      <td>-0.059925</td>\n",
       "      <td>-0.234705</td>\n",
       "      <td>-0.131524</td>\n",
       "      <td>-0.294843</td>\n",
       "      <td>0.828389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13362</td>\n",
       "      <td>216653</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.823033</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.891258</td>\n",
       "      <td>0.799278</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.203198</td>\n",
       "      <td>-0.168081</td>\n",
       "      <td>-0.425957</td>\n",
       "      <td>1.191440</td>\n",
       "      <td>-0.059925</td>\n",
       "      <td>-0.234705</td>\n",
       "      <td>-0.131524</td>\n",
       "      <td>-0.294843</td>\n",
       "      <td>0.828389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13362</td>\n",
       "      <td>216653</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.823033</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.891258</td>\n",
       "      <td>0.799278</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.203198</td>\n",
       "      <td>-0.168081</td>\n",
       "      <td>-0.425957</td>\n",
       "      <td>1.191440</td>\n",
       "      <td>-0.059925</td>\n",
       "      <td>-0.234705</td>\n",
       "      <td>-0.131524</td>\n",
       "      <td>-0.294843</td>\n",
       "      <td>0.828389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13362</td>\n",
       "      <td>216653</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.823033</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.891258</td>\n",
       "      <td>0.799278</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.203198</td>\n",
       "      <td>-0.168081</td>\n",
       "      <td>-0.425957</td>\n",
       "      <td>1.191440</td>\n",
       "      <td>-0.059925</td>\n",
       "      <td>-0.234705</td>\n",
       "      <td>-0.131524</td>\n",
       "      <td>-0.294843</td>\n",
       "      <td>0.828389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  song_id  target  idx  city       age  gender  registered_via  \\\n",
       "0    13362   232041       1    0     0 -0.823033       0               3   \n",
       "1    13362   232041       1    1     0 -0.823033       0               3   \n",
       "2    13362   232041       1    2     0 -0.823033       0               3   \n",
       "3    13362   232041       1    3     0 -0.823033       0               3   \n",
       "4    13362   216653       1    4     0 -0.823033       0               3   \n",
       "5    13362   216653       1    5     0 -0.823033       0               3   \n",
       "6    13362   216653       1    6     0 -0.823033       0               3   \n",
       "\n",
       "   weird_age  validate_days      ...       song_year  artist_count  \\\n",
       "0   0.891258       0.799278      ...              98     -0.203198   \n",
       "1   0.891258       0.799278      ...              98     -0.203198   \n",
       "2   0.891258       0.799278      ...              98     -0.203198   \n",
       "3   0.891258       0.799278      ...              98     -0.203198   \n",
       "4   0.891258       0.799278      ...              98     -0.203198   \n",
       "5   0.891258       0.799278      ...              98     -0.203198   \n",
       "6   0.891258       0.799278      ...              98     -0.203198   \n",
       "\n",
       "   genre_count  lyricist_count  composer_count  is_featured  artist_composer  \\\n",
       "0    -0.168081       -0.425957        0.591896    -0.059925        -0.234705   \n",
       "1    -0.168081       -0.425957        0.591896    -0.059925        -0.234705   \n",
       "2    -0.168081       -0.425957        0.591896    -0.059925        -0.234705   \n",
       "3    -0.168081       -0.425957        0.591896    -0.059925        -0.234705   \n",
       "4    -0.168081       -0.425957        1.191440    -0.059925        -0.234705   \n",
       "5    -0.168081       -0.425957        1.191440    -0.059925        -0.234705   \n",
       "6    -0.168081       -0.425957        1.191440    -0.059925        -0.234705   \n",
       "\n",
       "   artist_composer_lyricist  song_lang_boolean  smaller_song  \n",
       "0                 -0.131524          -0.294843      0.828389  \n",
       "1                 -0.131524          -0.294843      0.828389  \n",
       "2                 -0.131524          -0.294843      0.828389  \n",
       "3                 -0.131524          -0.294843      0.828389  \n",
       "4                 -0.131524          -0.294843      0.828389  \n",
       "5                 -0.131524          -0.294843      0.828389  \n",
       "6                 -0.131524          -0.294843      0.828389  \n",
       "\n",
       "[7 rows x 32 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_train.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aug_train.loc[aug_train['idx'] % 4 == 1, 'user_id'] = -1 # user cold start\n",
    "aug_train.loc[aug_train['idx'] % 4 == 2, 'song_id'] = -1 # item cold start\n",
    "aug_train.loc[aug_train['idx'] % 4 == 3, ['user_id', 'song_id']] = -1 # user/item both cold start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in user_CATEGORICAL + item_CATEGORICAL + ['user_id', 'song_id']:\n",
    "    aug_train[col] = aug_train[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(df):\n",
    "    ret = df.merge(df_user_context, on='user_id', how='left')\n",
    "    ret = ret.merge(df_song_context, on='song_id', how='left')\n",
    "    for col in user_CATEGORICAL + item_CATEGORICAL + ['user_id', 'song_id']:\n",
    "        ret[col] = ret[col].astype('category')\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(df):\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df['target']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = merge_df(data_train.df)\n",
    "test_warm = merge_df(data_test_warm.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change cold start user and item to -1\n",
    "test_cold_user = data_test_cold_user.df.merge(df_user_context, on='user_id', how='left')\n",
    "test_cold_user = test_cold_user.merge(df_song_context, on='song_id', how='left')\n",
    "test_cold_user['user_id'] = -1\n",
    "for col in user_CATEGORICAL + item_CATEGORICAL + ['user_id', 'song_id']:\n",
    "    test_cold_user[col] = test_cold_user[col].astype('category')\n",
    "\n",
    "test_cold_item = data_test_cold_item.df.merge(df_user_context, on='user_id', how='left')\n",
    "test_cold_item = test_cold_item.merge(df_song_context, on='song_id', how='left')\n",
    "test_cold_item['song_id'] = -1\n",
    "for col in user_CATEGORICAL + item_CATEGORICAL + ['user_id', 'song_id']:\n",
    "    test_cold_item[col] = test_cold_item[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = aug_train.drop(columns=['target', 'idx'])\n",
    "y = aug_train['target']\n",
    "X_trn, X_val, y_trn, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "d_trn = lgb.Dataset(X_trn, y_trn)\n",
    "d_val = lgb.Dataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_train = prepare_lgb_data(train)\n",
    "X_warm, y_warm = separate(test_warm)\n",
    "X_cold_user, y_cold_user = separate(test_cold_user)\n",
    "X_cold_item, y_cold_item = separate(test_cold_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary', # objective is the goal\n",
    "#     'objective': 'mse',\n",
    "    'metric': 'auc',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.3,\n",
    "    'verbose': 0,\n",
    "    'num_leaves': 108,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_seed': 1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'feature_fraction_seed': 1,\n",
    "    'max_bin': 256,\n",
    "    'max_depth': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'auc', 'boosting': 'gbdt', 'learning_rate': 0.3, 'verbose': 0, 'num_leaves': 108, 'bagging_fraction': 0.95, 'bagging_freq': 1, 'bagging_seed': 1, 'feature_fraction': 0.9, 'feature_fraction_seed': 1, 'max_bin': 256, 'max_depth': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:671: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's auc: 0.620949\n",
      "[10]\tvalid_0's auc: 0.636759\n",
      "[15]\tvalid_0's auc: 0.652243\n",
      "[20]\tvalid_0's auc: 0.658085\n",
      "[25]\tvalid_0's auc: 0.661378\n",
      "[30]\tvalid_0's auc: 0.669501\n",
      "[35]\tvalid_0's auc: 0.674469\n",
      "[40]\tvalid_0's auc: 0.677504\n",
      "[45]\tvalid_0's auc: 0.679189\n",
      "[50]\tvalid_0's auc: 0.680854\n",
      "[55]\tvalid_0's auc: 0.682444\n",
      "[60]\tvalid_0's auc: 0.684347\n",
      "[65]\tvalid_0's auc: 0.685323\n",
      "[70]\tvalid_0's auc: 0.688187\n",
      "[75]\tvalid_0's auc: 0.689293\n",
      "[80]\tvalid_0's auc: 0.690414\n",
      "[85]\tvalid_0's auc: 0.691734\n",
      "[90]\tvalid_0's auc: 0.692798\n",
      "[95]\tvalid_0's auc: 0.693765\n",
      "[100]\tvalid_0's auc: 0.696829\n",
      "[105]\tvalid_0's auc: 0.697749\n",
      "[110]\tvalid_0's auc: 0.698833\n",
      "[115]\tvalid_0's auc: 0.699518\n",
      "[120]\tvalid_0's auc: 0.700777\n",
      "[125]\tvalid_0's auc: 0.701556\n",
      "[130]\tvalid_0's auc: 0.702954\n",
      "[135]\tvalid_0's auc: 0.703714\n",
      "[140]\tvalid_0's auc: 0.705615\n",
      "[145]\tvalid_0's auc: 0.706365\n",
      "[150]\tvalid_0's auc: 0.707687\n",
      "[155]\tvalid_0's auc: 0.708138\n",
      "[160]\tvalid_0's auc: 0.708721\n",
      "[165]\tvalid_0's auc: 0.709779\n",
      "[170]\tvalid_0's auc: 0.710202\n",
      "[175]\tvalid_0's auc: 0.710629\n",
      "[180]\tvalid_0's auc: 0.713259\n",
      "[185]\tvalid_0's auc: 0.713655\n",
      "[190]\tvalid_0's auc: 0.714363\n",
      "[195]\tvalid_0's auc: 0.715954\n",
      "[200]\tvalid_0's auc: 0.716341\n",
      "[205]\tvalid_0's auc: 0.717166\n",
      "[210]\tvalid_0's auc: 0.717534\n",
      "[215]\tvalid_0's auc: 0.717913\n",
      "[220]\tvalid_0's auc: 0.718349\n",
      "[225]\tvalid_0's auc: 0.71884\n",
      "[230]\tvalid_0's auc: 0.71924\n",
      "[235]\tvalid_0's auc: 0.719524\n",
      "[240]\tvalid_0's auc: 0.721126\n",
      "[245]\tvalid_0's auc: 0.721471\n",
      "[250]\tvalid_0's auc: 0.723504\n",
      "[255]\tvalid_0's auc: 0.723923\n",
      "[260]\tvalid_0's auc: 0.724387\n",
      "[265]\tvalid_0's auc: 0.725079\n",
      "[270]\tvalid_0's auc: 0.725717\n",
      "[275]\tvalid_0's auc: 0.726261\n",
      "[280]\tvalid_0's auc: 0.727319\n",
      "[285]\tvalid_0's auc: 0.72799\n",
      "[290]\tvalid_0's auc: 0.728953\n",
      "[295]\tvalid_0's auc: 0.730045\n",
      "[300]\tvalid_0's auc: 0.730795\n",
      "[305]\tvalid_0's auc: 0.731089\n",
      "[310]\tvalid_0's auc: 0.731557\n",
      "[315]\tvalid_0's auc: 0.731815\n",
      "[320]\tvalid_0's auc: 0.732561\n",
      "[325]\tvalid_0's auc: 0.732809\n",
      "[330]\tvalid_0's auc: 0.733198\n",
      "[335]\tvalid_0's auc: 0.733566\n",
      "[340]\tvalid_0's auc: 0.734004\n",
      "[345]\tvalid_0's auc: 0.734283\n",
      "[350]\tvalid_0's auc: 0.73456\n",
      "[355]\tvalid_0's auc: 0.734911\n",
      "[360]\tvalid_0's auc: 0.735226\n",
      "[365]\tvalid_0's auc: 0.735614\n",
      "[370]\tvalid_0's auc: 0.736118\n",
      "[375]\tvalid_0's auc: 0.736792\n",
      "[380]\tvalid_0's auc: 0.737152\n",
      "[385]\tvalid_0's auc: 0.737488\n",
      "[390]\tvalid_0's auc: 0.737971\n",
      "[395]\tvalid_0's auc: 0.739006\n",
      "[400]\tvalid_0's auc: 0.73939\n",
      "[405]\tvalid_0's auc: 0.739815\n",
      "[410]\tvalid_0's auc: 0.740119\n",
      "[415]\tvalid_0's auc: 0.740355\n",
      "[420]\tvalid_0's auc: 0.740637\n",
      "[425]\tvalid_0's auc: 0.740924\n",
      "[430]\tvalid_0's auc: 0.741146\n",
      "[435]\tvalid_0's auc: 0.741431\n",
      "[440]\tvalid_0's auc: 0.741655\n",
      "[445]\tvalid_0's auc: 0.742005\n",
      "[450]\tvalid_0's auc: 0.742785\n",
      "[455]\tvalid_0's auc: 0.743409\n",
      "[460]\tvalid_0's auc: 0.743702\n",
      "[465]\tvalid_0's auc: 0.744095\n",
      "[470]\tvalid_0's auc: 0.745176\n",
      "[475]\tvalid_0's auc: 0.745435\n",
      "[480]\tvalid_0's auc: 0.745938\n",
      "[485]\tvalid_0's auc: 0.746268\n",
      "[490]\tvalid_0's auc: 0.746559\n",
      "[495]\tvalid_0's auc: 0.747074\n",
      "[500]\tvalid_0's auc: 0.747293\n"
     ]
    }
   ],
   "source": [
    "print(params)\n",
    "model_lgb = lgb.train(params, train_set=d_trn,  valid_sets=d_val, num_boost_round=500, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary', 'metric': 'auc', 'boosting': 'gbdt', 'learning_rate': 0.3, 'verbose': 0, 'num_leaves': 108, 'bagging_fraction': 0.95, 'bagging_freq': 1, 'bagging_seed': 1, 'feature_fraction': 0.9, 'feature_fraction_seed': 1, 'max_bin': 256, 'max_depth': 10, 'categorical_column': [0, 1, 2, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20]}\n",
      "[5]\tvalid_0's auc: 0.620949\n",
      "[10]\tvalid_0's auc: 0.636759\n",
      "[15]\tvalid_0's auc: 0.652243\n",
      "[20]\tvalid_0's auc: 0.658085\n",
      "[25]\tvalid_0's auc: 0.661378\n",
      "[30]\tvalid_0's auc: 0.669501\n",
      "[35]\tvalid_0's auc: 0.674469\n",
      "[40]\tvalid_0's auc: 0.677504\n",
      "[45]\tvalid_0's auc: 0.679189\n",
      "[50]\tvalid_0's auc: 0.680854\n",
      "[55]\tvalid_0's auc: 0.682444\n",
      "[60]\tvalid_0's auc: 0.684347\n",
      "[65]\tvalid_0's auc: 0.685323\n",
      "[70]\tvalid_0's auc: 0.688187\n",
      "[75]\tvalid_0's auc: 0.689293\n",
      "[80]\tvalid_0's auc: 0.690414\n",
      "[85]\tvalid_0's auc: 0.691734\n",
      "[90]\tvalid_0's auc: 0.692798\n",
      "[95]\tvalid_0's auc: 0.693765\n",
      "[100]\tvalid_0's auc: 0.696829\n",
      "[105]\tvalid_0's auc: 0.697749\n",
      "[110]\tvalid_0's auc: 0.698833\n",
      "[115]\tvalid_0's auc: 0.699518\n",
      "[120]\tvalid_0's auc: 0.700777\n",
      "[125]\tvalid_0's auc: 0.701556\n",
      "[130]\tvalid_0's auc: 0.702954\n",
      "[135]\tvalid_0's auc: 0.703714\n",
      "[140]\tvalid_0's auc: 0.705615\n",
      "[145]\tvalid_0's auc: 0.706365\n",
      "[150]\tvalid_0's auc: 0.707687\n",
      "[155]\tvalid_0's auc: 0.708138\n",
      "[160]\tvalid_0's auc: 0.708721\n",
      "[165]\tvalid_0's auc: 0.709779\n",
      "[170]\tvalid_0's auc: 0.710202\n",
      "[175]\tvalid_0's auc: 0.710629\n",
      "[180]\tvalid_0's auc: 0.713259\n",
      "[185]\tvalid_0's auc: 0.713655\n",
      "[190]\tvalid_0's auc: 0.714363\n",
      "[195]\tvalid_0's auc: 0.715954\n",
      "[200]\tvalid_0's auc: 0.716341\n",
      "[205]\tvalid_0's auc: 0.717166\n",
      "[210]\tvalid_0's auc: 0.717534\n",
      "[215]\tvalid_0's auc: 0.717913\n",
      "[220]\tvalid_0's auc: 0.718349\n",
      "[225]\tvalid_0's auc: 0.71884\n",
      "[230]\tvalid_0's auc: 0.71924\n",
      "[235]\tvalid_0's auc: 0.719524\n",
      "[240]\tvalid_0's auc: 0.721126\n",
      "[245]\tvalid_0's auc: 0.721471\n",
      "[250]\tvalid_0's auc: 0.723504\n",
      "[255]\tvalid_0's auc: 0.723923\n",
      "[260]\tvalid_0's auc: 0.724387\n",
      "[265]\tvalid_0's auc: 0.725079\n",
      "[270]\tvalid_0's auc: 0.725717\n",
      "[275]\tvalid_0's auc: 0.726261\n",
      "[280]\tvalid_0's auc: 0.727319\n",
      "[285]\tvalid_0's auc: 0.72799\n",
      "[290]\tvalid_0's auc: 0.728953\n",
      "[295]\tvalid_0's auc: 0.730045\n",
      "[300]\tvalid_0's auc: 0.730795\n",
      "[305]\tvalid_0's auc: 0.731089\n",
      "[310]\tvalid_0's auc: 0.731557\n",
      "[315]\tvalid_0's auc: 0.731815\n",
      "[320]\tvalid_0's auc: 0.732561\n",
      "[325]\tvalid_0's auc: 0.732809\n",
      "[330]\tvalid_0's auc: 0.733198\n",
      "[335]\tvalid_0's auc: 0.733566\n",
      "[340]\tvalid_0's auc: 0.734004\n",
      "[345]\tvalid_0's auc: 0.734283\n",
      "[350]\tvalid_0's auc: 0.73456\n",
      "[355]\tvalid_0's auc: 0.734911\n",
      "[360]\tvalid_0's auc: 0.735226\n",
      "[365]\tvalid_0's auc: 0.735614\n",
      "[370]\tvalid_0's auc: 0.736118\n",
      "[375]\tvalid_0's auc: 0.736792\n",
      "[380]\tvalid_0's auc: 0.737152\n",
      "[385]\tvalid_0's auc: 0.737488\n",
      "[390]\tvalid_0's auc: 0.737971\n",
      "[395]\tvalid_0's auc: 0.739006\n",
      "[400]\tvalid_0's auc: 0.73939\n",
      "[405]\tvalid_0's auc: 0.739815\n",
      "[410]\tvalid_0's auc: 0.740119\n",
      "[415]\tvalid_0's auc: 0.740355\n",
      "[420]\tvalid_0's auc: 0.740637\n",
      "[425]\tvalid_0's auc: 0.740924\n",
      "[430]\tvalid_0's auc: 0.741146\n",
      "[435]\tvalid_0's auc: 0.741431\n",
      "[440]\tvalid_0's auc: 0.741655\n",
      "[445]\tvalid_0's auc: 0.742005\n",
      "[450]\tvalid_0's auc: 0.742785\n",
      "[455]\tvalid_0's auc: 0.743409\n",
      "[460]\tvalid_0's auc: 0.743702\n",
      "[465]\tvalid_0's auc: 0.744095\n",
      "[470]\tvalid_0's auc: 0.745176\n",
      "[475]\tvalid_0's auc: 0.745435\n",
      "[480]\tvalid_0's auc: 0.745938\n",
      "[485]\tvalid_0's auc: 0.746268\n",
      "[490]\tvalid_0's auc: 0.746559\n",
      "[495]\tvalid_0's auc: 0.747074\n",
      "[500]\tvalid_0's auc: 0.747293\n",
      "[505]\tvalid_0's auc: 0.747594\n",
      "[510]\tvalid_0's auc: 0.747853\n",
      "[515]\tvalid_0's auc: 0.748535\n",
      "[520]\tvalid_0's auc: 0.749031\n",
      "[525]\tvalid_0's auc: 0.749641\n",
      "[530]\tvalid_0's auc: 0.749849\n",
      "[535]\tvalid_0's auc: 0.750114\n",
      "[540]\tvalid_0's auc: 0.750348\n",
      "[545]\tvalid_0's auc: 0.750746\n",
      "[550]\tvalid_0's auc: 0.751204\n",
      "[555]\tvalid_0's auc: 0.751456\n",
      "[560]\tvalid_0's auc: 0.751757\n",
      "[565]\tvalid_0's auc: 0.751977\n",
      "[570]\tvalid_0's auc: 0.752389\n",
      "[575]\tvalid_0's auc: 0.752708\n",
      "[580]\tvalid_0's auc: 0.752929\n",
      "[585]\tvalid_0's auc: 0.753175\n",
      "[590]\tvalid_0's auc: 0.753373\n",
      "[595]\tvalid_0's auc: 0.753606\n",
      "[600]\tvalid_0's auc: 0.754469\n",
      "[605]\tvalid_0's auc: 0.754853\n",
      "[610]\tvalid_0's auc: 0.755115\n",
      "[615]\tvalid_0's auc: 0.755315\n",
      "[620]\tvalid_0's auc: 0.755537\n",
      "[625]\tvalid_0's auc: 0.755752\n",
      "[630]\tvalid_0's auc: 0.756032\n",
      "[635]\tvalid_0's auc: 0.7563\n",
      "[640]\tvalid_0's auc: 0.756501\n",
      "[645]\tvalid_0's auc: 0.757014\n",
      "[650]\tvalid_0's auc: 0.757229\n",
      "[655]\tvalid_0's auc: 0.757446\n",
      "[660]\tvalid_0's auc: 0.757628\n",
      "[665]\tvalid_0's auc: 0.758112\n",
      "[670]\tvalid_0's auc: 0.758725\n",
      "[675]\tvalid_0's auc: 0.758932\n",
      "[680]\tvalid_0's auc: 0.759209\n",
      "[685]\tvalid_0's auc: 0.759421\n",
      "[690]\tvalid_0's auc: 0.7596\n",
      "[695]\tvalid_0's auc: 0.76041\n",
      "[700]\tvalid_0's auc: 0.760644\n",
      "[705]\tvalid_0's auc: 0.760849\n",
      "[710]\tvalid_0's auc: 0.761074\n",
      "[715]\tvalid_0's auc: 0.761333\n",
      "[720]\tvalid_0's auc: 0.761876\n",
      "[725]\tvalid_0's auc: 0.762086\n",
      "[730]\tvalid_0's auc: 0.762304\n",
      "[735]\tvalid_0's auc: 0.762478\n",
      "[740]\tvalid_0's auc: 0.762627\n",
      "[745]\tvalid_0's auc: 0.762904\n",
      "[750]\tvalid_0's auc: 0.763049\n",
      "[755]\tvalid_0's auc: 0.763231\n",
      "[760]\tvalid_0's auc: 0.763413\n",
      "[765]\tvalid_0's auc: 0.76407\n",
      "[770]\tvalid_0's auc: 0.764442\n",
      "[775]\tvalid_0's auc: 0.76473\n",
      "[780]\tvalid_0's auc: 0.765064\n",
      "[785]\tvalid_0's auc: 0.765288\n",
      "[790]\tvalid_0's auc: 0.765498\n",
      "[795]\tvalid_0's auc: 0.765684\n",
      "[800]\tvalid_0's auc: 0.765908\n",
      "[805]\tvalid_0's auc: 0.76618\n",
      "[810]\tvalid_0's auc: 0.766414\n",
      "[815]\tvalid_0's auc: 0.766611\n",
      "[820]\tvalid_0's auc: 0.766818\n",
      "[825]\tvalid_0's auc: 0.76706\n",
      "[830]\tvalid_0's auc: 0.767268\n",
      "[835]\tvalid_0's auc: 0.767425\n",
      "[840]\tvalid_0's auc: 0.767706\n",
      "[845]\tvalid_0's auc: 0.767856\n",
      "[850]\tvalid_0's auc: 0.767984\n",
      "[855]\tvalid_0's auc: 0.768235\n",
      "[860]\tvalid_0's auc: 0.768395\n",
      "[865]\tvalid_0's auc: 0.768633\n",
      "[870]\tvalid_0's auc: 0.768961\n",
      "[875]\tvalid_0's auc: 0.769139\n",
      "[880]\tvalid_0's auc: 0.769297\n",
      "[885]\tvalid_0's auc: 0.769509\n",
      "[890]\tvalid_0's auc: 0.769681\n",
      "[895]\tvalid_0's auc: 0.769839\n",
      "[900]\tvalid_0's auc: 0.770049\n",
      "[905]\tvalid_0's auc: 0.770198\n",
      "[910]\tvalid_0's auc: 0.770329\n",
      "[915]\tvalid_0's auc: 0.770481\n",
      "[920]\tvalid_0's auc: 0.77063\n",
      "[925]\tvalid_0's auc: 0.770837\n",
      "[930]\tvalid_0's auc: 0.771051\n",
      "[935]\tvalid_0's auc: 0.771265\n",
      "[940]\tvalid_0's auc: 0.771443\n",
      "[945]\tvalid_0's auc: 0.77176\n",
      "[950]\tvalid_0's auc: 0.772159\n",
      "[955]\tvalid_0's auc: 0.772368\n",
      "[960]\tvalid_0's auc: 0.772548\n",
      "[965]\tvalid_0's auc: 0.772693\n",
      "[970]\tvalid_0's auc: 0.772869\n",
      "[975]\tvalid_0's auc: 0.773187\n",
      "[980]\tvalid_0's auc: 0.773439\n",
      "[985]\tvalid_0's auc: 0.7736\n",
      "[990]\tvalid_0's auc: 0.773882\n",
      "[995]\tvalid_0's auc: 0.77407\n",
      "[1000]\tvalid_0's auc: 0.774457\n",
      "[1005]\tvalid_0's auc: 0.774648\n",
      "[1010]\tvalid_0's auc: 0.775194\n",
      "[1015]\tvalid_0's auc: 0.775385\n",
      "[1020]\tvalid_0's auc: 0.775624\n",
      "[1025]\tvalid_0's auc: 0.775789\n",
      "[1030]\tvalid_0's auc: 0.775909\n",
      "[1035]\tvalid_0's auc: 0.776047\n",
      "[1040]\tvalid_0's auc: 0.776753\n",
      "[1045]\tvalid_0's auc: 0.77695\n",
      "[1050]\tvalid_0's auc: 0.777163\n",
      "[1055]\tvalid_0's auc: 0.777311\n",
      "[1060]\tvalid_0's auc: 0.777455\n",
      "[1065]\tvalid_0's auc: 0.777663\n",
      "[1070]\tvalid_0's auc: 0.777782\n",
      "[1075]\tvalid_0's auc: 0.777954\n",
      "[1080]\tvalid_0's auc: 0.7781\n",
      "[1085]\tvalid_0's auc: 0.778268\n",
      "[1090]\tvalid_0's auc: 0.778459\n",
      "[1095]\tvalid_0's auc: 0.778586\n",
      "[1100]\tvalid_0's auc: 0.77873\n",
      "[1105]\tvalid_0's auc: 0.778869\n",
      "[1110]\tvalid_0's auc: 0.778961\n",
      "[1115]\tvalid_0's auc: 0.779119\n",
      "[1120]\tvalid_0's auc: 0.779307\n",
      "[1125]\tvalid_0's auc: 0.779472\n",
      "[1130]\tvalid_0's auc: 0.779596\n",
      "[1135]\tvalid_0's auc: 0.779723\n",
      "[1140]\tvalid_0's auc: 0.779821\n",
      "[1145]\tvalid_0's auc: 0.779944\n",
      "[1150]\tvalid_0's auc: 0.780137\n",
      "[1155]\tvalid_0's auc: 0.780282\n",
      "[1160]\tvalid_0's auc: 0.780383\n",
      "[1165]\tvalid_0's auc: 0.780755\n",
      "[1170]\tvalid_0's auc: 0.781103\n",
      "[1175]\tvalid_0's auc: 0.781254\n",
      "[1180]\tvalid_0's auc: 0.781388\n",
      "[1185]\tvalid_0's auc: 0.781574\n",
      "[1190]\tvalid_0's auc: 0.781712\n",
      "[1195]\tvalid_0's auc: 0.781842\n",
      "[1200]\tvalid_0's auc: 0.782015\n",
      "[1205]\tvalid_0's auc: 0.782137\n",
      "[1210]\tvalid_0's auc: 0.78233\n",
      "[1215]\tvalid_0's auc: 0.782481\n",
      "[1220]\tvalid_0's auc: 0.782628\n",
      "[1225]\tvalid_0's auc: 0.782744\n",
      "[1230]\tvalid_0's auc: 0.783036\n",
      "[1235]\tvalid_0's auc: 0.783355\n",
      "[1240]\tvalid_0's auc: 0.783497\n",
      "[1245]\tvalid_0's auc: 0.783923\n",
      "[1250]\tvalid_0's auc: 0.784252\n",
      "[1255]\tvalid_0's auc: 0.784379\n",
      "[1260]\tvalid_0's auc: 0.784622\n",
      "[1265]\tvalid_0's auc: 0.78477\n",
      "[1270]\tvalid_0's auc: 0.784893\n",
      "[1275]\tvalid_0's auc: 0.785035\n",
      "[1280]\tvalid_0's auc: 0.785158\n",
      "[1285]\tvalid_0's auc: 0.785288\n",
      "[1290]\tvalid_0's auc: 0.785425\n",
      "[1295]\tvalid_0's auc: 0.785539\n",
      "[1300]\tvalid_0's auc: 0.785672\n",
      "[1305]\tvalid_0's auc: 0.785822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1310]\tvalid_0's auc: 0.785919\n",
      "[1315]\tvalid_0's auc: 0.78602\n",
      "[1320]\tvalid_0's auc: 0.786164\n",
      "[1325]\tvalid_0's auc: 0.786252\n",
      "[1330]\tvalid_0's auc: 0.786349\n",
      "[1335]\tvalid_0's auc: 0.786451\n",
      "[1340]\tvalid_0's auc: 0.786544\n",
      "[1345]\tvalid_0's auc: 0.786622\n",
      "[1350]\tvalid_0's auc: 0.786709\n",
      "[1355]\tvalid_0's auc: 0.786797\n",
      "[1360]\tvalid_0's auc: 0.786992\n",
      "[1365]\tvalid_0's auc: 0.787105\n",
      "[1370]\tvalid_0's auc: 0.787208\n",
      "[1375]\tvalid_0's auc: 0.787326\n",
      "[1380]\tvalid_0's auc: 0.787422\n",
      "[1385]\tvalid_0's auc: 0.787525\n",
      "[1390]\tvalid_0's auc: 0.787666\n",
      "[1395]\tvalid_0's auc: 0.787796\n",
      "[1400]\tvalid_0's auc: 0.787933\n",
      "[1405]\tvalid_0's auc: 0.788086\n",
      "[1410]\tvalid_0's auc: 0.788187\n",
      "[1415]\tvalid_0's auc: 0.788286\n",
      "[1420]\tvalid_0's auc: 0.788371\n",
      "[1425]\tvalid_0's auc: 0.788461\n",
      "[1430]\tvalid_0's auc: 0.788586\n",
      "[1435]\tvalid_0's auc: 0.78867\n",
      "[1440]\tvalid_0's auc: 0.788756\n",
      "[1445]\tvalid_0's auc: 0.78885\n",
      "[1450]\tvalid_0's auc: 0.78894\n",
      "[1455]\tvalid_0's auc: 0.789059\n",
      "[1460]\tvalid_0's auc: 0.789133\n",
      "[1465]\tvalid_0's auc: 0.789219\n",
      "[1470]\tvalid_0's auc: 0.789312\n",
      "[1475]\tvalid_0's auc: 0.789426\n",
      "[1480]\tvalid_0's auc: 0.789505\n",
      "[1485]\tvalid_0's auc: 0.789607\n",
      "[1490]\tvalid_0's auc: 0.789724\n",
      "[1495]\tvalid_0's auc: 0.789822\n",
      "[1500]\tvalid_0's auc: 0.789908\n",
      "[1505]\tvalid_0's auc: 0.789991\n",
      "[1510]\tvalid_0's auc: 0.790052\n",
      "[1515]\tvalid_0's auc: 0.790136\n",
      "[1520]\tvalid_0's auc: 0.790231\n",
      "[1525]\tvalid_0's auc: 0.790307\n",
      "[1530]\tvalid_0's auc: 0.790408\n",
      "[1535]\tvalid_0's auc: 0.790493\n",
      "[1540]\tvalid_0's auc: 0.790585\n",
      "[1545]\tvalid_0's auc: 0.790658\n",
      "[1550]\tvalid_0's auc: 0.790749\n",
      "[1555]\tvalid_0's auc: 0.790868\n",
      "[1560]\tvalid_0's auc: 0.790958\n",
      "[1565]\tvalid_0's auc: 0.791022\n",
      "[1570]\tvalid_0's auc: 0.791105\n",
      "[1575]\tvalid_0's auc: 0.791202\n",
      "[1580]\tvalid_0's auc: 0.79129\n",
      "[1585]\tvalid_0's auc: 0.791394\n",
      "[1590]\tvalid_0's auc: 0.791496\n",
      "[1595]\tvalid_0's auc: 0.791583\n",
      "[1600]\tvalid_0's auc: 0.791676\n",
      "[1605]\tvalid_0's auc: 0.791751\n",
      "[1610]\tvalid_0's auc: 0.79185\n",
      "[1615]\tvalid_0's auc: 0.791943\n",
      "[1620]\tvalid_0's auc: 0.792097\n",
      "[1625]\tvalid_0's auc: 0.792209\n",
      "[1630]\tvalid_0's auc: 0.792299\n",
      "[1635]\tvalid_0's auc: 0.792402\n",
      "[1640]\tvalid_0's auc: 0.792485\n",
      "[1645]\tvalid_0's auc: 0.792572\n",
      "[1650]\tvalid_0's auc: 0.792658\n",
      "[1655]\tvalid_0's auc: 0.792739\n",
      "[1660]\tvalid_0's auc: 0.79285\n",
      "[1665]\tvalid_0's auc: 0.792938\n",
      "[1670]\tvalid_0's auc: 0.793023\n",
      "[1675]\tvalid_0's auc: 0.793131\n",
      "[1680]\tvalid_0's auc: 0.79321\n",
      "[1685]\tvalid_0's auc: 0.793405\n",
      "[1690]\tvalid_0's auc: 0.793506\n",
      "[1695]\tvalid_0's auc: 0.793592\n",
      "[1700]\tvalid_0's auc: 0.793779\n",
      "[1705]\tvalid_0's auc: 0.793864\n",
      "[1710]\tvalid_0's auc: 0.793937\n",
      "[1715]\tvalid_0's auc: 0.794024\n",
      "[1720]\tvalid_0's auc: 0.794119\n",
      "[1725]\tvalid_0's auc: 0.79419\n",
      "[1730]\tvalid_0's auc: 0.794272\n",
      "[1735]\tvalid_0's auc: 0.794383\n",
      "[1740]\tvalid_0's auc: 0.794451\n",
      "[1745]\tvalid_0's auc: 0.794539\n",
      "[1750]\tvalid_0's auc: 0.794608\n",
      "[1755]\tvalid_0's auc: 0.79468\n",
      "[1760]\tvalid_0's auc: 0.794758\n",
      "[1765]\tvalid_0's auc: 0.794831\n",
      "[1770]\tvalid_0's auc: 0.794894\n",
      "[1775]\tvalid_0's auc: 0.794988\n",
      "[1780]\tvalid_0's auc: 0.795083\n",
      "[1785]\tvalid_0's auc: 0.795163\n",
      "[1790]\tvalid_0's auc: 0.795249\n",
      "[1795]\tvalid_0's auc: 0.795339\n",
      "[1800]\tvalid_0's auc: 0.795413\n",
      "[1805]\tvalid_0's auc: 0.79548\n",
      "[1810]\tvalid_0's auc: 0.795581\n",
      "[1815]\tvalid_0's auc: 0.795638\n",
      "[1820]\tvalid_0's auc: 0.795707\n",
      "[1825]\tvalid_0's auc: 0.795779\n",
      "[1830]\tvalid_0's auc: 0.795862\n",
      "[1835]\tvalid_0's auc: 0.795934\n",
      "[1840]\tvalid_0's auc: 0.796017\n",
      "[1845]\tvalid_0's auc: 0.796428\n",
      "[1850]\tvalid_0's auc: 0.796813\n",
      "[1855]\tvalid_0's auc: 0.796954\n",
      "[1860]\tvalid_0's auc: 0.797085\n",
      "[1865]\tvalid_0's auc: 0.797338\n",
      "[1870]\tvalid_0's auc: 0.797476\n",
      "[1875]\tvalid_0's auc: 0.79759\n",
      "[1880]\tvalid_0's auc: 0.797681\n",
      "[1885]\tvalid_0's auc: 0.797829\n",
      "[1890]\tvalid_0's auc: 0.797916\n",
      "[1895]\tvalid_0's auc: 0.797997\n",
      "[1900]\tvalid_0's auc: 0.798127\n",
      "[1905]\tvalid_0's auc: 0.798216\n",
      "[1910]\tvalid_0's auc: 0.798316\n",
      "[1915]\tvalid_0's auc: 0.798406\n",
      "[1920]\tvalid_0's auc: 0.798488\n",
      "[1925]\tvalid_0's auc: 0.798572\n",
      "[1930]\tvalid_0's auc: 0.798671\n",
      "[1935]\tvalid_0's auc: 0.798748\n",
      "[1940]\tvalid_0's auc: 0.798837\n",
      "[1945]\tvalid_0's auc: 0.798945\n",
      "[1950]\tvalid_0's auc: 0.799019\n",
      "[1955]\tvalid_0's auc: 0.799111\n",
      "[1960]\tvalid_0's auc: 0.79919\n",
      "[1965]\tvalid_0's auc: 0.799271\n",
      "[1970]\tvalid_0's auc: 0.799347\n",
      "[1975]\tvalid_0's auc: 0.799421\n",
      "[1980]\tvalid_0's auc: 0.799486\n",
      "[1985]\tvalid_0's auc: 0.799554\n",
      "[1990]\tvalid_0's auc: 0.799652\n",
      "[1995]\tvalid_0's auc: 0.799728\n",
      "[2000]\tvalid_0's auc: 0.799853\n"
     ]
    }
   ],
   "source": [
    "print(params)\n",
    "model_lgb = lgb.train(params, train_set=d_trn,  valid_sets=d_val, num_boost_round=2000, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def recall_gbdt(klist, data, X):\n",
    "    df = data.df\n",
    "    df['score'] = model_lgb.predict(X, raw_score=True)\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    for user in data.user_list:\n",
    "        # compute the scores\n",
    "        score_list = np.ravel(df[df['user_id'] == user]['score'])\n",
    "        \n",
    "        # get the recommended list\n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def recall_score_model(klist, data, v_user_all, v_item_all):\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    for user in data.user_list:\n",
    "        # get the corresponding embedded vectors\n",
    "        v_user = v_user_all[user]\n",
    "        v_item = v_item_all[data.item_list[user]]\n",
    "        \n",
    "        # compute the scores\n",
    "        score_list = np.matmul(v_user, v_item.T)\n",
    "        score_list = score_list.flatten()\n",
    "        # assert len(score_list) == len(data.item_list[user])\n",
    "        \n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        # get the recommended list\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-06 12:01:00] (start) evaluation of gbdt\n",
      "{'objective': 'binary', 'metric': 'auc', 'boosting': 'gbdt', 'learning_rate': 0.3, 'verbose': 0, 'num_leaves': 108, 'bagging_fraction': 0.95, 'bagging_freq': 1, 'bagging_seed': 1, 'feature_fraction': 0.9, 'feature_fraction_seed': 1, 'max_bin': 256, 'max_depth': 10, 'categorical_column': [0, 1, 2, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20]}\n",
      "test warm\n",
      "[ 0.20346529  0.42537291  0.60613683  0.73533932  0.82024982  0.87847102\n",
      "  0.91585342  0.94104802  0.95753832  0.96846961]\n",
      "[ 0.26750232  0.49173467  0.65854236  0.77200428  0.84624367  0.89548443\n",
      "  0.92770755  0.94943105  0.96372148  0.97313665]\n",
      "[ 0.2686829   0.49468758  0.66080657  0.77434248  0.84793419  0.89708983\n",
      "  0.92893367  0.95018285  0.96445685  0.97367826]\n",
      "\n",
      "test cold user\n",
      "[ 0.54573009  0.67572377  0.75811542  0.81760581  0.86168741  0.895074\n",
      "  0.92072266  0.94126276  0.95609972  0.96705006]\n",
      "[ 0.54603787  0.67667078  0.75895311  0.81788323  0.8618485   0.89507481\n",
      "  0.92072056  0.94114917  0.95592356  0.96690828]\n",
      "[ 0.56268494  0.69237101  0.77282308  0.82961689  0.87144192  0.90310455\n",
      "  0.92728894  0.94609048  0.95963913  0.96979196]\n",
      "\n",
      "test cold item\n",
      "[ 0.50637507  0.66540974  0.75248465  0.80983578  0.8482495   0.8768385\n",
      "  0.89739997  0.91307577  0.92530568  0.93604244]\n",
      "[ 0.5093784   0.66603463  0.75262869  0.80965487  0.84824089  0.87682556\n",
      "  0.89752886  0.91310884  0.92520717  0.93597828]\n",
      "[ 0.53449666  0.68838719  0.77155249  0.82522326  0.86154956  0.88779239\n",
      "  0.90678941  0.92115016  0.93203841  0.94178659]\n",
      "\n",
      "[2018-05-06 12:07:09] ( end ) evaluation of gbdt [time elapsed: 0:06:09]\n"
     ]
    }
   ],
   "source": [
    "sub_timer.start('evaluation of gbdt')\n",
    "# 2000 epoch\n",
    "print(params)\n",
    "klist = list(range(5, 51, 5))\n",
    "# print('train')\n",
    "# print(recall_random(klist, data_train))\n",
    "# print(recall_score_model(klist, data_train, v_user_all, v_item_all))\n",
    "# print(recall_gbdt(klist, data_train, X))\n",
    "# print()\n",
    "\n",
    "print('test warm')\n",
    "print(recall_random(klist, data_test_warm))\n",
    "print(recall_score_model(klist, data_test_warm, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_warm, X_warm))\n",
    "print()\n",
    "\n",
    "print('test cold user')\n",
    "print(recall_random(klist, data_test_cold_user))\n",
    "print(recall_score_model(klist, data_test_cold_user, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_cold_user, X_cold_user))\n",
    "print()\n",
    "\n",
    "print('test cold item')\n",
    "print(recall_random(klist, data_test_cold_item))\n",
    "print(recall_score_model(klist, data_test_cold_item, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_cold_item, X_cold_item))\n",
    "print()\n",
    "sub_timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-06 10:37:42] (start) evaluation of gbdt\n",
      "{'objective': 'binary', 'metric': 'auc', 'boosting': 'gbdt', 'learning_rate': 0.3, 'verbose': 0, 'num_leaves': 108, 'bagging_fraction': 0.95, 'bagging_freq': 1, 'bagging_seed': 1, 'feature_fraction': 0.9, 'feature_fraction_seed': 1, 'max_bin': 256, 'max_depth': 10, 'categorical_column': [0, 1, 2, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20]}\n",
      "test warm\n",
      "[ 0.20374156  0.42586533  0.60641282  0.73545119  0.82023161  0.87811316\n",
      "  0.91560563  0.94066219  0.95740171  0.96831204]\n",
      "[ 0.26750232  0.49173467  0.65854236  0.77200428  0.84624367  0.89548443\n",
      "  0.92770755  0.94943105  0.96372148  0.97313665]\n",
      "[ 0.26476547  0.48998216  0.65737527  0.77163501  0.84618241  0.89583185\n",
      "  0.92813701  0.94954964  0.96401957  0.97339108]\n",
      "\n",
      "test cold user\n",
      "[ 0.54531909  0.67531644  0.75770807  0.81759664  0.86180726  0.89516004\n",
      "  0.92096013  0.94126592  0.95599291  0.9669299 ]\n",
      "[ 0.54603787  0.67667078  0.75895311  0.81788323  0.8618485   0.89507481\n",
      "  0.92072056  0.94114917  0.95592356  0.96690828]\n",
      "[ 0.56368288  0.69306626  0.77360887  0.8304738   0.87201351  0.90344879\n",
      "  0.92750832  0.9463934   0.95986453  0.96995309]\n",
      "\n",
      "test cold item\n",
      "[ 0.50739205  0.66569703  0.75288312  0.80974952  0.84821177  0.87663642\n",
      "  0.89740231  0.9129612   0.92511331  0.93597513]\n",
      "[ 0.5093784   0.66603463  0.75262869  0.80965487  0.84824089  0.87682556\n",
      "  0.89752886  0.91310884  0.92520717  0.93597828]\n",
      "[ 0.52976308  0.68442204  0.76850084  0.82312654  0.85966576  0.88619715\n",
      "  0.90544891  0.91970231  0.93090068  0.94083529]\n",
      "\n",
      "[2018-05-06 10:39:32] ( end ) evaluation of gbdt [time elapsed: 0:01:50]\n"
     ]
    }
   ],
   "source": [
    "sub_timer.start('evaluation of gbdt')\n",
    "# 500 epoch\n",
    "print(params)\n",
    "klist = list(range(5, 51, 5))\n",
    "# print('train')\n",
    "# print(recall_random(klist, data_train))\n",
    "# print(recall_score_model(klist, data_train, v_user_all, v_item_all))\n",
    "# print(recall_gbdt(klist, data_train, X))\n",
    "# print()\n",
    "\n",
    "print('test warm')\n",
    "print(recall_random(klist, data_test_warm))\n",
    "print(recall_score_model(klist, data_test_warm, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_warm, X_warm))\n",
    "print()\n",
    "\n",
    "print('test cold user')\n",
    "print(recall_random(klist, data_test_cold_user))\n",
    "print(recall_score_model(klist, data_test_cold_user, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_cold_user, X_cold_user))\n",
    "print()\n",
    "\n",
    "print('test cold item')\n",
    "print(recall_random(klist, data_test_cold_item))\n",
    "print(recall_score_model(klist, data_test_cold_item, v_user_all, v_item_all))\n",
    "print(recall_gbdt(klist, data_test_cold_item, X_cold_item))\n",
    "print()\n",
    "sub_timer.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archived"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
