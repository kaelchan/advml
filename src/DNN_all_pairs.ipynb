{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04 18:04:39\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer():\n",
    "    def __init__(self):\n",
    "        self.info = 'main'\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def start(self, info):\n",
    "        self.info = info\n",
    "        self.start_time = time.time()\n",
    "        self.checkpoint('start', elapsed_on=False)\n",
    "    \n",
    "    def end(self):\n",
    "        self.checkpoint(' end ')\n",
    "        \n",
    "    def checkpoint(self, tag, elapsed_on=True):\n",
    "        if elapsed_on:\n",
    "            elapsed = datetime.timedelta(seconds=round(time.time() - self.start_time))\n",
    "            expanded_info = self.info + ' [time elapsed: %s]' % str(elapsed)\n",
    "        else:\n",
    "            expanded_info = self.info\n",
    "        self.output(tag, info=expanded_info)\n",
    "        \n",
    "    def output(self, tag=' '*5, info=''):\n",
    "        if type(info) != type(''):\n",
    "            info = str(info)\n",
    "        print('[%s] (%s) %s' % (Timer.get_current_time(), tag, info))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_current_time():\n",
    "        return time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "timer = Timer()\n",
    "sub_timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-04 18:04:39] (start) Load Data\n"
     ]
    }
   ],
   "source": [
    "timer.start('Load Data')\n",
    "# directory = '../data/split/'\n",
    "# df_train = pd.read_csv(directory + 'train.csv')\n",
    "# df_test_warm = pd.read_csv(directory + 'test_warm.csv')\n",
    "# df_test_cold_user = pd.read_csv(directory + 'test_cold_user.csv')\n",
    "# df_test_cold_item = pd.read_csv(directory + 'test_cold_item.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-04 18:04:40] (context) Load Data [time elapsed: 0:00:01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory = '../data/context/'\n",
    "# df_event_context = pd.read_csv(directory + 'event_context.csv')\n",
    "df_song_context = pd.read_csv(directory + 'song_context.csv')\n",
    "df_user_context = pd.read_csv(directory + 'user_context.csv')\n",
    "timer.checkpoint('context')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30755\n",
      "359966\n"
     ]
    }
   ],
   "source": [
    "num_user = len(df_user_context.user_id.unique())\n",
    "num_item = len(df_song_context.song_id.unique())\n",
    "print (num_user)\n",
    "print (num_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load target sets\n",
    "# import pickle\n",
    "# with open('../data/split/target_set.pickle', 'rb') as handle:\n",
    "#     target_set = pickle.load(handle)\n",
    "# with open('../data/split/train_target_set.pickle', 'rb') as handle:\n",
    "#     train_target_set = pickle.load(handle)\n",
    "# with open('../data/split/test_warm_target_set.pickle', 'rb') as handle:\n",
    "#     test_warm_target_set = pickle.load(handle)\n",
    "# with open('../data/split/test_cold_user_target_set.pickle', 'rb') as handle:\n",
    "#     test_cold_user_target_set = pickle.load(handle)\n",
    "# with open('../data/split/test_cold_item_target_set.pickle', 'rb') as handle:\n",
    "#     test_cold_item_target_set = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, name):\n",
    "        '''\n",
    "        user_list: list(int), the list of user id's used in the dataset\n",
    "        target_set: list(set), set of target items for each user\n",
    "        item_list: list(numpy array), list of items used in the dataset for each user\n",
    "        '''\n",
    "        self.name = name\n",
    "        self.df = None\n",
    "        self.user_list = None\n",
    "        self.item_list = None\n",
    "        self.target_set = None\n",
    "    \n",
    "    def load(self, filename):\n",
    "        self.df = pd.read_csv(filename)\n",
    "        # prepare user list\n",
    "        self.user_list = self.df['user_id'].unique()\n",
    "        \n",
    "        # prepare item list\n",
    "        self.item_list = [[] for i in range(num_user)]\n",
    "        self.df.apply(\n",
    "            lambda row: self.item_list[row['user_id']].append(row['song_id']),\n",
    "            axis=1\n",
    "        )\n",
    "        self.item_list = list(map(np.array, self.item_list))\n",
    "        \n",
    "        # prepare target set\n",
    "        self.target_set = [set() for i in range(num_user)]\n",
    "        self.df[self.df['target'] == 1].apply(\n",
    "            lambda row: self.target_set[row['user_id']].add(row['song_id']),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "# def load_split(name):\n",
    "#     data = Data(name)\n",
    "#     # load the user ids in the data set\n",
    "#     with open('../data/split/' + name + '_user_list.pickle', 'rb') as handle:\n",
    "#         data.user_list = pickle.load(handle)\n",
    "        \n",
    "#     # load the list(set) for items in the data set with label=1\n",
    "#     with open('../data/split/' + name + '_target_set.pickle', 'rb') as handle:\n",
    "#         data.target_set = pickle.load(handle)\n",
    "        \n",
    "#     # load the list(set) for all items in the data set\n",
    "#     with open('../data/split/' + name + '_item_set.pickle', 'rb') as handle:\n",
    "#         data.item_set = pickle.load(handle)\n",
    "        \n",
    "#     return data\n",
    "\n",
    "def load_split(name):\n",
    "    directory = '../data/split/'\n",
    "    data = Data(name)\n",
    "    data.load(directory + name + '.csv')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-04 18:08:04] ( end ) Load Data [time elapsed: 0:03:25]\n"
     ]
    }
   ],
   "source": [
    "# data_train = load_split('train')\n",
    "# data_test_warm = load_split('test_warm')\n",
    "# data_test_cold_user = load_split('test_cold_user')\n",
    "# data_test_cold_item = load_split('test_cold_item')\n",
    "\n",
    "data_train = load_split('train')\n",
    "data_test_warm = load_split('test_warm')\n",
    "data_test_cold_user = load_split('test_cold_user')\n",
    "data_test_cold_item = load_split('test_cold_item')\n",
    "timer.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Unnamed: 0', u'user_id', u'song_id', u'target'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_train.df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Activation, Reshape, Lambda\n",
    "from keras.layers.merge import concatenate, dot\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform, RandomNormal, TruncatedNormal, Zeros\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "REG_LAMBDA = 0\n",
    "EMBED_DIM = 64\n",
    "\n",
    "vocab_size = num_user\n",
    "user_embeddings = Embedding(\n",
    "    input_dim = vocab_size,\n",
    "    output_dim = EMBED_DIM,\n",
    "    embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "    embeddings_regularizer = l2(REG_LAMBDA),\n",
    "    input_length = 1,\n",
    "    name = 'user_embed',\n",
    "    trainable=True)\n",
    "\n",
    "vocab_size = num_item\n",
    "item_embeddings = Embedding(\n",
    "    input_dim = vocab_size,\n",
    "    output_dim = EMBED_DIM,\n",
    "    embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "    embeddings_regularizer=l2(REG_LAMBDA),\n",
    "    input_length=1,\n",
    "    name = 'item_embed',\n",
    "    trainable=True)\n",
    "\n",
    "# embedding of user id\n",
    "uid_input = Input(shape=(1,), dtype='int32')\n",
    "embedded_user = user_embeddings(uid_input)\n",
    "embedded_user = Reshape((EMBED_DIM,))(embedded_user)\n",
    "\n",
    "# embedding of song id\n",
    "iid_input = Input(shape=(1,), dtype='int32')\n",
    "embedded_item = item_embeddings(iid_input)\n",
    "embedded_item = Reshape((EMBED_DIM,))(embedded_item)\n",
    "\n",
    "# dot production of embedded vectors\n",
    "preds = dot([embedded_user, embedded_item], axes=1, name='dot_score')\n",
    "\n",
    "# embedding model\n",
    "user_embed_model = Model(inputs=uid_input, outputs=embedded_user)\n",
    "item_embed_model = Model(inputs=iid_input, outputs=embedded_item)\n",
    "\n",
    "model_MF = Model(inputs=[uid_input, iid_input], outputs=preds)\n",
    "model_MF.compile(\n",
    "    loss=keras.losses.mean_squared_error, \n",
    "    optimizer=RMSprop(lr=1e-3),\n",
    "#     optimizer=SGD(lr=1e-4),\n",
    "    metrics=[keras.metrics.mean_squared_error])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = '../model/mf/'\n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)\n",
    "model_path = model_directory + 'mf_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_model_path = '../model/dropout/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model_MF.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_top_k(score_list, k):\n",
    "    ind = np.argpartition(score_list, -k)[-k:]\n",
    "    top_k_ind = list(reversed(ind[np.argsort(score_list[ind])]))\n",
    "    return np.array(top_k_ind)\n",
    "\n",
    "# try to implement a two-dimensional top_k\n",
    "def two_dim_top_k(a, k):\n",
    "    return np.array([single_top_k(row, k) for row in a])\n",
    "\n",
    "def top_k(a, k):\n",
    "    if len(a.shape) == 1:\n",
    "        return single_top_k(a, k)\n",
    "    elif len(a.shape) == 2:\n",
    "        return two_dim_top_k(a, k)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 64)\n",
      "[[  2.59375989e-01  -3.29650007e-02   4.17865440e-02   1.46565601e-01]\n",
      " [ -6.12905342e-03   2.17780974e-02  -5.20521775e-03  -2.27784272e-04]]\n",
      "[ 0.25937599 -0.032965    0.04178654  0.1465656 ]\n"
     ]
    }
   ],
   "source": [
    "user = 1\n",
    "item_list = np.array([1,2,3,4])\n",
    "v_user = user_embed_model.predict(np.array([1, 2]))\n",
    "v_item = item_embed_model.predict(item_list)\n",
    "\n",
    "print(v_user.shape)\n",
    "\n",
    "#_x = v_user @ v_item.T #require python 3.5\n",
    "_x = np.matmul(v_user, v_item.T)\n",
    "print(_x)\n",
    "\n",
    "print(model_MF.predict([\n",
    "    np.repeat(user, len(item_list)),\n",
    "    item_list\n",
    "]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 19)\n"
     ]
    }
   ],
   "source": [
    "print(len(data_test_warm.item_list[1]), len(data_test_warm.target_set[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recall at k\n",
    "sess = tf.Session()\n",
    "v_user_all = user_embed_model.predict(np.arange(num_user))\n",
    "v_item_all = item_embed_model.predict(np.arange(num_item))\n",
    "    \n",
    "def __recall(klist, target, recommend_list):\n",
    "    den = len(target) # denominator\n",
    "    recall_value = 0.0\n",
    "    recall_list = []\n",
    "    for k in klist:\n",
    "        if den < k:\n",
    "            recall_value = 1.0\n",
    "        if recall_value == 1.0: # if it's already 1.0, it should be 1.0 after\n",
    "            recall_list.append(recall_value)\n",
    "            continue\n",
    "        recommend_set = set(recommend_list[:k])\n",
    "        num = len(target & recommend_set)\n",
    "        recall_value = float(num) / float(den)\n",
    "        recall_list.append(recall_value)\n",
    "    return recall_list\n",
    "\n",
    "\n",
    "def recall_mf(model, klist, data):\n",
    "    '''\n",
    "    :param klist: the list of k's in recall@k, e.g. [50, 100, 150, ...]\n",
    "    :param data: data set for evaluation\n",
    "        - user_list\n",
    "        - target_set\n",
    "        - item_set\n",
    "    :return: list(float) for recall at each k, with the same size as klist\n",
    "    '''\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    t1, t2, t3, t4, t5 = 0, 0, 0, 0, 0\n",
    "    for user in data.user_list:\n",
    "        # get the corresponding embedded vectors\n",
    "        v_user = v_user_all[user]\n",
    "        v_item = v_item_all[data.item_list[user]]\n",
    "        \n",
    "        # compute the scores\n",
    "        #score_list = v_user @ v_item.T\n",
    "        score_list = np.matmul(v_user, v_item.T)\n",
    "        score_list = score_list.flatten()\n",
    "        # assert len(score_list) == len(data.item_list[user])\n",
    "        \n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        # get the recommended list\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)\n",
    "\n",
    "\n",
    "def recall_random(klist, data):\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    for i, user in enumerate(data.user_list):\n",
    "        # compute the scores\n",
    "        score_list = np.random.uniform(low=0, high=1, size=len(data.item_list[user]))\n",
    "        \n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will be quite slow: each user takes around 4s to run.\n",
    "\n",
    "```\n",
    "score_list = model_MF.predict([\n",
    "    np.repeat(user, len(item_list)),\n",
    "    item_list\n",
    "]).flatten()\n",
    "```\n",
    "\n",
    "**It's because fetching embeddings are slow.** So get the embedding first and use matrix multiplication!\n",
    "\n",
    "After modification, it will still take > 30 mintues (I don't know how long...)\n",
    "\n",
    "### Note!!\n",
    "\n",
    "It's **far more** better to get more from the model at one time rather than calling the model multiple times!\n",
    "\n",
    "The difference between warm and cold is due to the difference in denominator (maybe), so don't compare them with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Dropout Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Unnamed: 0', 'user_id'}, set())"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_CATEGORICAL = [\n",
    "    'city', 'gender', 'registered_via', 'registration_year', \n",
    "    'registration_month', 'registration_day', 'expiration_year', \n",
    "    'expiration_month', 'expiration_day']\n",
    "user_NUMERICAL = ['age', 'weird_age', 'validate_days']\n",
    "set(df_user_context.columns) - (set(user_CATEGORICAL).union(set(user_NUMERICAL))), \\\n",
    "set(user_CATEGORICAL).intersection(set(user_NUMERICAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Unnamed: 0', 'song_id'}, set())"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_CATEGORICAL = [\n",
    "    'artist_name', 'composer', 'genre_ids', 'language', \n",
    "    'lyricist', 'song_year']\n",
    "item_NUMERICAL = [\n",
    "    'song_length', 'genre_count', 'lyricist_count',\n",
    "    'composer_count', 'artist_count', 'is_featured',\n",
    "    'artist_composer', 'artist_composer_lyricist', \n",
    "    'song_lang_boolean', 'smaller_song']\n",
    "set(df_song_context.columns) - (set(item_CATEGORICAL).union(set(item_NUMERICAL))), \\\n",
    "set(item_CATEGORICAL).intersection(set(item_NUMERICAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cold(x, recall_at):\n",
    "    embedding_prod_cold = tf.matual(x[0], x[1], transpose_b = True, name='pred_all_items')\n",
    "    _, eval_preds_cold = tf.nn.top_k(embedding_prod_cold, k=recall_at[-1], sorted=True, name='topK_net_cold')\n",
    "    return eval_preds_cold\n",
    "\n",
    "def evaluate_warm(x, recall_at):\n",
    "    embedding_prod_cold = tf.matual(x[0], x[1], transpose_b = True)\n",
    "    embedding_prod_warm = tf.sparse_add(embedding_prod_cold, x[2])\n",
    "    _, eval_preds_warm = tf.nn.top_k(embedding_prod_warm, k=recall_at[-1], sorted=True, name='topK_net_warm')\n",
    "    return eval_preds_warm\n",
    "\n",
    "def prediction(x):\n",
    "    return tf.matmul(x[0], x[1], transpose_b=True)\n",
    "\n",
    "def topk_vals(x, num_candidates):\n",
    "    tf_topk_vals, _ = tf.nn.top_k(x, k=num_candidates, sorted=True)\n",
    "    return tf.reshape(tf_topk_vals, [-1], name='select_y_vals')\n",
    "\n",
    "def topk_inds(x, num_candidates):\n",
    "    _, tf_topk_inds = tf.nn.top_k(x, k=num_candidates, sorted=True)\n",
    "    return tf.reshape(tf_topk_inds, [-1], name='select_y_vals')\n",
    "\n",
    "def random_target(x, num_candidates):\n",
    "    preds_random = tf.gather_nd(x[0], x[1])\n",
    "    return tf.reshape(preds_random, [-1], name='random_y_inds')\n",
    "\n",
    "def latent_topk_cold(x, recall_at):\n",
    "    _, tf_latent_topk_cold = tf.nn.top_k(x, k=recall_at[-1], sorted=True, name='topK_latent_cold')\n",
    "    return tf_latent_topk_cold\n",
    "\n",
    "def latent_topk_warm(x, recall_at):\n",
    "    preds_pref_latent_warm = tf.sparse_add(x[0], x[1])\n",
    "    _, tf_latent_topk_warm = tf.nn.top_k(preds_pref_latent_warm, k=recall_at[-1], sorted=True, name='topK_latent_warm')\n",
    "    return tf_latent_topk_warm\n",
    "\n",
    "def dense_batch_fc_tanh(x, units, scope, do_norm=False):\n",
    "#     w_init = tf.truncated_normal_initializer(stddev=0.01)\n",
    "#     b_init = tf.zeros_initializer()\n",
    "#     h1 = Dense(units, kernel_initializer = w_init, bias_initializer = b_init)(x)\n",
    "    h1 = Dense(units, kernel_initializer = TruncatedNormal(stddev=0.01), bias_initializer = Zeros())(x)\n",
    "    if do_norm:\n",
    "        # h2 = BatchNormalization(momentum = 0.9, center=True, scale=True, training=phase)(h1)\n",
    "        h2 = BatchNormalization(momentum = 0.9, center=True, scale=True)(h1)\n",
    "        return Activation('tanh')(h2)\n",
    "    else:\n",
    "        return Activation('tanh')(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCF:\n",
    "    \"\"\"\n",
    "    main model class implementing DeepCF\n",
    "    also stores states for fast candidate generation\n",
    "\n",
    "    latent_rank_in: rank of preference model input\n",
    "    user_content_rank: rank of user content input\n",
    "    item_content_rank: rank of item content input\n",
    "    model_select: array of number of hidden unit,\n",
    "        i.e. [200,100] indicate two hidden layer with 200 units followed by 100 units\n",
    "    rank_out: rank of latent model output\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_rank_in, model_select, rank_out):\n",
    "        self.rank_in = latent_rank_in\n",
    "        self.model_select = model_select\n",
    "        self.rank_out = rank_out\n",
    "\n",
    "    def context_model(self, tag, df_context, CATEGORICAL, NUMERICAL):\n",
    "        input_layers = []\n",
    "        embed_layers = []\n",
    "        for col in CATEGORICAL:\n",
    "            input_layer = Input(shape=(1,), name=tag + '_' + col + '_input')\n",
    "            input_layers.append(input_layer)\n",
    "            vocab_size = df_context[col].max() + 1\n",
    "            embed_size = np.power(2, int(np.ceil(np.log2(np.log2(vocab_size)))))\n",
    "            print('[%s] %-20s\\tvocab: %-8d, embed: %-4d' % (tag, col, vocab_size, embed_size))\n",
    "            embed_layer = Embedding(\n",
    "                input_dim = vocab_size,\n",
    "                output_dim = embed_size,\n",
    "                embeddings_initializer = RandomUniform(minval=-0.1, maxval=0.1),\n",
    "                embeddings_regularizer = l2(1e-4),\n",
    "                input_length = 1,\n",
    "                name = tag + '_' + col+'_embed',\n",
    "                trainable=True)\n",
    "            embed_layer = embed_layer(input_layer)\n",
    "            embed_layer = Reshape((embed_size,))(embed_layer)\n",
    "            embed_layers.append(embed_layer)\n",
    "            \n",
    "        numerical_input = Input(shape=(len(NUMERICAL),), name=tag+'_numerical_input')\n",
    "        input_layers.append(numerical_input)\n",
    "        \n",
    "        preds = concatenate(embed_layers + [numerical_input], name=tag + '_content')\n",
    "#         preds = Dense(64, activation='relu', name=tag + '_content_dense1')(preds)\n",
    "#         preds = Dropout(0.5, name=tag + '_content_dropout')(preds)\n",
    "#         preds = Dense(64, name=tag + '_content_dense1')(preds)\n",
    "        return input_layers, preds\n",
    "            \n",
    "    def build_model(self):\n",
    "        self.Vin = Input(shape=(self.rank_in,), dtype='float32', name='V_in_raw')\n",
    "        self.Uin = Input(shape=(self.rank_in,), dtype='float32', name='U_in_raw')\n",
    "        \n",
    "        self.user_inputs, self.Ucontent = self.context_model(\n",
    "            'user', df_user_context, CATEGORICAL=user_CATEGORICAL, NUMERICAL=user_NUMERICAL)\n",
    "        self.item_inputs, self.Vcontent = self.context_model(\n",
    "            'item', df_song_context, CATEGORICAL=item_CATEGORICAL, NUMERICAL=item_NUMERICAL)\n",
    "        \n",
    "        u_concat = concatenate([self.Uin, self.Ucontent])\n",
    "        v_concat = concatenate([self.Vin, self.Vcontent])\n",
    "        u_last = u_concat\n",
    "        v_last = v_concat\n",
    "        for ihid, hid in enumerate(self.model_select):\n",
    "            u_last = dense_batch_fc_tanh(u_last, hid, 'user_layer_%d' % (ihid + 1), do_norm=True)\n",
    "            v_last = dense_batch_fc_tanh(v_last, hid, 'item_layer_%d' % (ihid + 1), do_norm=True)\n",
    "\n",
    "        self.U_embedding = Dense(\n",
    "            self.rank_out, \n",
    "            kernel_initializer = TruncatedNormal(stddev=0.01),\n",
    "            bias_initializer = Zeros())(u_last)\n",
    "        self.V_embedding = Dense(\n",
    "            self.rank_out, \n",
    "            kernel_initializer = TruncatedNormal(stddev=0.01),\n",
    "            bias_initializer = Zeros())(v_last)\n",
    "        self.preds = dot([self.U_embedding, self.V_embedding], axes=1, name='dot_score')\n",
    "        self.input_layers = [self.Uin, self.Vin] + self.user_inputs + self.item_inputs\n",
    "        \n",
    "        self.user_model = Model(inputs=[self.Uin] + self.user_inputs, outputs=self.U_embedding)\n",
    "        self.item_model = Model(inputs=[self.Vin] + self.item_inputs, outputs=self.V_embedding)\n",
    "        \n",
    "        model = Model(inputs=self.input_layers, outputs=self.preds)\n",
    "        # optimizer = RMSprop()\n",
    "        optimizer = RMSprop(lr=5e-3)\n",
    "        model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user] city                \tvocab: 21      , embed: 8   \n",
      "[user] gender              \tvocab: 3       , embed: 2   \n",
      "[user] registered_via      \tvocab: 5       , embed: 4   \n",
      "[user] registration_year   \tvocab: 14      , embed: 4   \n",
      "[user] registration_month  \tvocab: 12      , embed: 4   \n",
      "[user] registration_day    \tvocab: 31      , embed: 8   \n",
      "[user] expiration_year     \tvocab: 18      , embed: 8   \n",
      "[user] expiration_month    \tvocab: 12      , embed: 4   \n",
      "[user] expiration_day      \tvocab: 31      , embed: 8   \n",
      "[item] artist_name         \tvocab: 40583   , embed: 16  \n",
      "[item] composer            \tvocab: 76064   , embed: 32  \n",
      "[item] genre_ids           \tvocab: 573     , embed: 16  \n",
      "[item] language            \tvocab: 10      , embed: 4   \n",
      "[item] lyricist            \tvocab: 33888   , embed: 16  \n",
      "[item] song_year           \tvocab: 100     , embed: 8   \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_city_input (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_gender_input (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_registered_via_input (Inpu (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_registration_year_input (I (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_registration_month_input ( (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_registration_day_input (In (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_year_input (Inp (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_month_input (In (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_day_input (Inpu (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_artist_name_input (InputLa (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_composer_input (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_genre_ids_input (InputLaye (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_language_input (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_lyricist_input (InputLayer (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_song_year_input (InputLaye (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_city_embed (Embedding)     (None, 1, 8)         168         user_city_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "user_gender_embed (Embedding)   (None, 1, 2)         6           user_gender_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "user_registered_via_embed (Embe (None, 1, 4)         20          user_registered_via_input[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "user_registration_year_embed (E (None, 1, 4)         56          user_registration_year_input[0][0\n",
      "__________________________________________________________________________________________________\n",
      "user_registration_month_embed ( (None, 1, 4)         48          user_registration_month_input[0][\n",
      "__________________________________________________________________________________________________\n",
      "user_registration_day_embed (Em (None, 1, 8)         248         user_registration_day_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_year_embed (Emb (None, 1, 8)         144         user_expiration_year_input[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_month_embed (Em (None, 1, 4)         48          user_expiration_month_input[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "user_expiration_day_embed (Embe (None, 1, 8)         248         user_expiration_day_input[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "item_artist_name_embed (Embeddi (None, 1, 16)        649328      item_artist_name_input[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "item_composer_embed (Embedding) (None, 1, 32)        2434048     item_composer_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "item_genre_ids_embed (Embedding (None, 1, 16)        9168        item_genre_ids_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "item_language_embed (Embedding) (None, 1, 4)         40          item_language_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "item_lyricist_embed (Embedding) (None, 1, 16)        542208      item_lyricist_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "item_song_year_embed (Embedding (None, 1, 8)         800         item_song_year_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 8)            0           user_city_embed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 2)            0           user_gender_embed[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 4)            0           user_registered_via_embed[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 4)            0           user_registration_year_embed[0][0\n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 4)            0           user_registration_month_embed[0][\n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 8)            0           user_registration_day_embed[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 8)            0           user_expiration_year_embed[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 4)            0           user_expiration_month_embed[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 8)            0           user_expiration_day_embed[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "user_numerical_input (InputLaye (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 16)           0           item_artist_name_embed[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 32)           0           item_composer_embed[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 16)           0           item_genre_ids_embed[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 4)            0           item_language_embed[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 16)           0           item_lyricist_embed[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 8)            0           item_song_year_embed[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "item_numerical_input (InputLaye (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "U_in_raw (InputLayer)           (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_content (Concatenate)      (None, 53)           0           reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "                                                                 reshape_11[0][0]                 \n",
      "                                                                 user_numerical_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "V_in_raw (InputLayer)           (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_content (Concatenate)      (None, 102)          0           reshape_12[0][0]                 \n",
      "                                                                 reshape_13[0][0]                 \n",
      "                                                                 reshape_14[0][0]                 \n",
      "                                                                 reshape_15[0][0]                 \n",
      "                                                                 reshape_16[0][0]                 \n",
      "                                                                 reshape_17[0][0]                 \n",
      "                                                                 item_numerical_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 117)          0           U_in_raw[0][0]                   \n",
      "                                                                 user_content[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 166)          0           V_in_raw[0][0]                   \n",
      "                                                                 item_content[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 200)          23600       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 200)          33400       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200)          800         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200)          800         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 200)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 200)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          20100       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 100)          20100       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 100)          400         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 100)          400         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 100)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 100)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          10100       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 100)          10100       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_score (Dot)                 (None, 1)            0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,756,378\n",
      "Trainable params: 3,755,178\n",
      "Non-trainable params: 1,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_rank_in = 64\n",
    "model_select = [200, 100]\n",
    "rank_out = 100\n",
    "\n",
    "dropout_net = DeepCF(latent_rank_in, model_select, rank_out)\n",
    "dropout_net.build_model()\n",
    "dropout_net.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stopwatch():\n",
    "    def __init__(self, info=''):\n",
    "        self.total = 0\n",
    "        self.info = info\n",
    "    \n",
    "    def clear(self):\n",
    "        self.total = 0\n",
    "    \n",
    "    def tic(self):\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def toc(self):\n",
    "        self.total += time.time() - self.start_time\n",
    "    \n",
    "    def show(self):\n",
    "        print('%.3f seconds \\t %s' % (self.total, self.info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_content(user_list):\n",
    "    return [df_user_context.loc[user_list, col] for col in user_CATEGORICAL] + [df_user_context.loc[user_list, user_NUMERICAL]]\n",
    "        \n",
    "def generate_item_content(item_list):\n",
    "    return [df_song_context.loc[item_list, col] for col in item_CATEGORICAL] + [df_song_context.loc[item_list, item_NUMERICAL]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_array_flat_join(list_of_list):\n",
    "    return np.ravel(list_of_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "user_batch_size = 1000\n",
    "# n_scores_user = 2500\n",
    "n_scores_user = 100\n",
    "\n",
    "data_batch_size = 100\n",
    "max_data_per_step = 2500000\n",
    "dropout = 0.5\n",
    "\n",
    "# counting variables\n",
    "n_step = 0\n",
    "n_batch_trained = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "u_pref = v_user_all\n",
    "v_pref = v_item_all\n",
    "_, u_pref_scaled = utils.prep_standardize(u_pref)\n",
    "_, v_pref_scaled = utils.prep_standardize(v_pref)\n",
    "v_pref_expanded = np.vstack([v_pref_scaled, np.zeros_like(v_pref_scaled[0, :])])\n",
    "v_pref_last = v_pref_scaled.shape[0] # the last v_pref_scaled TODO: maybe a all zero?\n",
    "u_pref_expanded = np.vstack([u_pref_scaled, np.zeros_like(u_pref_scaled[0, :])])\n",
    "u_pref_last = u_pref_scaled.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get top k matrix, the i-th row is the top k items for the i-th user\n",
    "# stopwatch = Stopwatch()\n",
    "# stopwatch.tic()\n",
    "# topK_matrix = [top_k(np.matmul(u_pref[i], v_pref.T), k = n_scores_user) for i in range(num_user)]\n",
    "# topK_matrix = np.array(topK_matrix)\n",
    "# stopwatch.toc()\n",
    "# stopwatch.show() # around 600s = 10min\n",
    "\n",
    "# # dump the topK_matrix\n",
    "# import pickle\n",
    "# with open('../model/mf/topK_matrix.pickle', 'wb') as handle:\n",
    "#     pickle.dump(topK_matrix, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pickle\\nwith open('../model/mf/topK_matrix.pickle', 'rb') as handle:\\n    topK_matrix = pickle.load(handle)\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pickle\n",
    "with open('../model/mf/topK_matrix.pickle', 'rb') as handle:\n",
    "    topK_matrix = pickle.load(handle)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30755, 14)\n",
      "(359966, 18)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect() # collect unused memory\n",
    "\n",
    "print (df_user_context.shape)\n",
    "print (df_song_context.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_target_scores = data_train.df['target']\n",
    "whole_target_items = data_train.df['song_id']\n",
    "whole_target_users = data_train.df['user_id']\n",
    "target_users = numpy_array_flat_join(whole_target_users)\n",
    "target_items = numpy_array_flat_join(whole_target_items)\n",
    "target_scores = numpy_array_flat_join(whole_target_scores)\n",
    "user_content = generate_user_content(target_users)\n",
    "item_content = generate_item_content(target_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_target_scores = data_train.df['target']\n",
    "whole_target_items = data_train.df['song_id']\n",
    "whole_target_users = data_train.df['user_id']\n",
    "target_users = numpy_array_flat_join(whole_target_users)\n",
    "target_items = numpy_array_flat_join(whole_target_items)\n",
    "target_scores = numpy_array_flat_join(whole_target_scores)\n",
    "user_content = generate_user_content(target_users)\n",
    "item_content = generate_item_content(target_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-04 18:21:15] (start) training\n",
      "Epoch 1/1\n",
      "5776897/5776897 [==============================] - 843s 146us/step - loss: 0.3755\n",
      "Epoch 1/1\n",
      "5776897/5776897 [==============================] - 835s 145us/step - loss: 0.2408\n",
      "Epoch 1/1\n",
      "5776897/5776897 [==============================] - 833s 144us/step - loss: 0.2463\n",
      "Epoch 1/1\n",
      "5776897/5776897 [==============================] - 838s 145us/step - loss: 0.2490\n",
      "Epoch 1/1\n",
      "5776897/5776897 [==============================] - 837s 145us/step - loss: 0.2505\n",
      "Epoch 1/1\n",
      " 248900/5776897 [>.............................] - ETA: 13:30 - loss: 0.2510"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6a1831d530c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     36\u001b[0m     \u001b[0msw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timer.start('training')\n",
    "# profiling\n",
    "sw = [Stopwatch() for _ in range(20)]\n",
    "\n",
    "num_epoch = 10\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    whole_target_scores = data_train.df['target']\n",
    "    whole_target_items = data_train.df['song_id']\n",
    "    whole_target_users = data_train.df['user_id']\n",
    "    target_users = numpy_array_flat_join(whole_target_users)\n",
    "    target_items = numpy_array_flat_join(whole_target_items)\n",
    "    target_scores = numpy_array_flat_join(whole_target_scores)\n",
    "    # user_content = generate_user_content(target_users)\n",
    "    # item_content = generate_item_content(target_items)\n",
    "    # dropout process\n",
    "    sw[0].tic()\n",
    "    n_targets = len(target_scores)\n",
    "    # n_targets = min(n_targets, max_data_per_step)\n",
    "    n_to_drop = int(np.floor(dropout * n_targets))\n",
    "    user_to_drop = np.random.choice(np.arange(n_targets), size=n_to_drop, replace=False)\n",
    "    item_to_drop = np.random.choice(np.arange(n_targets), size=n_to_drop, replace=False)\n",
    "    target_users[user_to_drop] = u_pref_last\n",
    "    target_items[item_to_drop] = v_pref_last\n",
    "    sw[0].toc()\n",
    "\n",
    "    sw[1].tic()\n",
    "    loss_out = dropout_net.model.fit(\n",
    "        x = [u_pref_expanded[target_users, :], v_pref_expanded[target_items, :]] + user_content + item_content,\n",
    "        y = target_scores, # target\n",
    "        epochs = 1,\n",
    "        batch_size = data_batch_size,\n",
    "        shuffle = True\n",
    "    )\n",
    "    sw[1].toc()\n",
    "    dropout_model_path = '../model/dropout/exp4/model_{}.h5'.format(epoch)\n",
    "    dropout_net.model.save_weights(dropout_model_path)\n",
    "timer.end()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.279 seconds \t \n",
      "1 4198.628 seconds \t \n",
      "2 0.000 seconds \t \n",
      "3 0.000 seconds \t \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint (target_users.shape)\\nprint (target_users[0])\\nprint (target_items.shape)\\nprint (target_items[0])\\nprint (target_scores.shape)\\nprint (target_scores[0])\\nprint (user_content[0])\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(4):\n",
    "    print (i),\n",
    "    sw[i].show()\n",
    "\n",
    "'''\n",
    "print (target_users.shape)\n",
    "print (target_users[0])\n",
    "print (target_items.shape)\n",
    "print (target_items[0])\n",
    "print (target_scores.shape)\n",
    "print (target_scores[0])\n",
    "print (user_content[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def recall_score_model(klist, data, v_user_all, v_item_all):\n",
    "    recall_at_k = []\n",
    "    max_k = max(klist)\n",
    "    for user in data.user_list:\n",
    "        # get the corresponding embedded vectors\n",
    "        v_user = v_user_all[user]\n",
    "        v_item = v_item_all[data.item_list[user]]\n",
    "        \n",
    "        # compute the scores\n",
    "        score_list = np.matmul(v_user, v_item.T)\n",
    "        score_list = score_list.flatten()\n",
    "        # assert len(score_list) == len(data.item_list[user])\n",
    "        \n",
    "        k = min(max_k, len(data.item_list[user]))\n",
    "        # get the recommended list\n",
    "        indices = top_k(score_list, k)\n",
    "        recommend_list = data.item_list[user][indices]\n",
    "        \n",
    "        # evaluate recall\n",
    "        recall_at_k.append(__recall(klist, data.target_set[user], recommend_list))\n",
    "    return np.mean(recall_at_k, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-05-04 19:32:54] (start) evaluation of dropout net\n",
      "----------------------------------------\n",
      "../model/dropout/exp4/model_0.h5\n",
      "train\n",
      "[ 0.28370769  0.31343705  0.33458298  0.35277255  0.37245938  0.3920868\n",
      "  0.41105624  0.43102104  0.45119718  0.47025535]\n",
      "[ 0.31106296  0.35011179  0.38146012  0.40964138  0.4366865   0.46233263\n",
      "  0.48666695  0.51054204  0.53342427  0.55493316]\n",
      "[ 0.29563337  0.33247172  0.36047015  0.38481439  0.40908825  0.43262741\n",
      "  0.45480657  0.47742201  0.49926586  0.51981998]\n",
      "()\n",
      "test warm\n",
      "[ 0.20369509  0.42504709  0.60636495  0.73519956  0.81980774  0.87788197\n",
      "  0.91545069  0.94064763  0.9575676   0.96841789]\n",
      "[ 0.26710343  0.49271289  0.65882621  0.77231052  0.84637798  0.89566094\n",
      "  0.92805651  0.94954364  0.96388396  0.97326312]\n",
      "[ 0.25824677  0.48350911  0.65220264  0.76794231  0.84310657  0.89351458\n",
      "  0.92640252  0.94854345  0.9631508   0.97267241]\n",
      "()\n",
      "test cold user\n",
      "[ 0.54575721  0.67547653  0.75783025  0.81714086  0.86131953  0.89488207\n",
      "  0.92068491  0.94106453  0.9559101   0.96688851]\n",
      "[ 0.54652435  0.67637865  0.75882391  0.81771064  0.86201169  0.89518416\n",
      "  0.92084417  0.94130998  0.95601549  0.96692114]\n",
      "[ 0.54951555  0.67880593  0.76139267  0.82030858  0.86414494  0.89699515\n",
      "  0.92230367  0.94236665  0.95676473  0.96763982]\n",
      "()\n",
      "test cold item\n",
      "[ 0.5072069   0.66590291  0.75291904  0.81008076  0.84847225  0.87696171\n",
      "  0.89742879  0.91307549  0.92532832  0.93618948]\n",
      "[ 0.50933396  0.66704784  0.75334558  0.81032999  0.84887929  0.87725017\n",
      "  0.89779317  0.91337293  0.92534461  0.93613338]\n",
      "[ 0.50863698  0.66664096  0.75325775  0.81027247  0.84892543  0.87706738\n",
      "  0.89753021  0.91312191  0.925279    0.93606787]\n",
      "()\n",
      "----------------------------------------\n",
      "../model/dropout/exp4/model_1.h5\n",
      "train\n",
      "[ 0.28380041  0.31364609  0.33469611  0.35282849  0.37242084  0.39200837\n",
      "  0.41097393  0.43115618  0.45126243  0.47047777]\n",
      "[ 0.31106296  0.35011179  0.38146012  0.40964138  0.4366865   0.46233263\n",
      "  0.48666695  0.51054204  0.53342427  0.55493316]\n",
      "[ 0.29208882  0.32814959  0.35485933  0.37768646  0.40092794  0.42344047\n",
      "  0.44475418  0.4667038   0.48795033  0.50822662]\n",
      "()\n",
      "test warm\n",
      "[ 0.20375802  0.42472865  0.6065966   0.73509224  0.81993991  0.87779672\n",
      "  0.91543364  0.94074934  0.95750793  0.96846733]\n",
      "[ 0.26710343  0.49271289  0.65882621  0.77231052  0.84637798  0.89566094\n",
      "  0.92805651  0.94954364  0.96388396  0.97326312]\n",
      "[ 0.25048824  0.47453264  0.6454118   0.76326227  0.83989005  0.89114582\n",
      "  0.92488635  0.94741082  0.96230535  0.97206905]\n",
      "()\n",
      "test cold user\n",
      "[ 0.54515748  0.67527702  0.75811709  0.81740953  0.86174893  0.895063\n",
      "  0.92080657  0.94127541  0.95611314  0.96707835]\n",
      "[ 0.54652435  0.67637865  0.75882391  0.81771064  0.86201169  0.89518416\n",
      "  0.92084417  0.94130998  0.95601549  0.96692114]\n",
      "[ 0.5619508   0.69007811  0.77030075  0.82699695  0.86898101  0.90065023\n",
      "  0.92513979  0.94413266  0.95809818  0.96841973]\n",
      "()\n",
      "test cold item\n",
      "[ 0.50631843  0.66531456  0.75264555  0.8099797   0.84850862  0.87693738\n",
      "  0.89751934  0.91310275  0.92528849  0.93599873]\n",
      "[ 0.50933396  0.66704784  0.75334558  0.81032999  0.84887929  0.87725017\n",
      "  0.89779317  0.91337293  0.92534461  0.93613338]\n",
      "[ 0.50885919  0.66636096  0.75276965  0.8098234   0.84833967  0.876843\n",
      "  0.89753776  0.91322764  0.92539426  0.93618621]\n",
      "()\n",
      "----------------------------------------\n",
      "../model/dropout/exp4/model_2.h5\n",
      "train\n",
      "[ 0.28398762  0.31339395  0.33471162  0.35284     0.37246496  0.39194488\n",
      "  0.4109639   0.43108324  0.45121204  0.47036688]\n",
      "[ 0.31106296  0.35011179  0.38146012  0.40964138  0.4366865   0.46233263\n",
      "  0.48666695  0.51054204  0.53342427  0.55493316]\n",
      "[ 0.29057561  0.32600382  0.35231659  0.37493324  0.39816275  0.42081656\n",
      "  0.44229158  0.46436422  0.48589307  0.50618876]\n",
      "()\n",
      "test warm\n",
      "[ 0.20365387  0.42550624  0.60682797  0.73550752  0.81989943  0.87795257\n",
      "  0.91568676  0.94062806  0.95741996  0.96834696]\n",
      "[ 0.26710343  0.49271289  0.65882621  0.77231052  0.84637798  0.89566094\n",
      "  0.92805651  0.94954364  0.96388396  0.97326312]\n",
      "[ 0.2472091   0.47071528  0.64239451  0.76058381  0.83824511  0.89011777\n",
      "  0.92388954  0.94668908  0.96183359  0.97161641]\n",
      "()\n",
      "test cold user\n",
      "[ 0.54545521  0.67547522  0.75762439  0.81717021  0.86131614  0.89473828\n",
      "  0.92070357  0.94117982  0.95605441  0.96690341]\n",
      "[ 0.54652435  0.67637865  0.75882391  0.81771064  0.86201169  0.89518416\n",
      "  0.92084417  0.94130998  0.95601549  0.96692114]\n",
      "[ 0.54644473  0.67744047  0.76013806  0.81882682  0.86247962  0.89573603\n",
      "  0.92125142  0.94140671  0.95616598  0.96707844]\n",
      "()\n",
      "test cold item\n",
      "[ 0.50643797  0.66522158  0.75266281  0.80982451  0.84826554  0.87648893\n",
      "  0.89720112  0.91280903  0.9250925   0.93590489]\n",
      "[ 0.50933396  0.66704784  0.75334558  0.81032999  0.84887929  0.87725017\n",
      "  0.89779317  0.91337293  0.92534461  0.93613338]\n",
      "[ 0.50946884  0.6665085   0.75278645  0.80980424  0.84848094  0.87691851\n",
      "  0.89760084  0.91331466  0.92534766  0.93613252]\n",
      "()\n",
      "----------------------------------------\n",
      "../model/dropout/exp4/model_3.h5\n",
      "train\n",
      "[ 0.28376504  0.31336685  0.33469467  0.35297671  0.37245867  0.3919892\n",
      "  0.41093621  0.43111877  0.45111127  0.47025686]\n",
      "[ 0.31106296  0.35011179  0.38146012  0.40964138  0.4366865   0.46233263\n",
      "  0.48666695  0.51054204  0.53342427  0.55493316]\n",
      "[ 0.28839574  0.3226917   0.34802012  0.36972807  0.39217319  0.41410252\n",
      "  0.43491048  0.45636236  0.47727585  0.49707603]\n",
      "()\n",
      "test warm\n",
      "[ 0.20347881  0.42509964  0.60590291  0.73523215  0.8200553   0.87810025\n",
      "  0.91559455  0.94077194  0.95750953  0.96842395]\n",
      "[ 0.26710343  0.49271289  0.65882621  0.77231052  0.84637798  0.89566094\n",
      "  0.92805651  0.94954364  0.96388396  0.97326312]\n",
      "[ 0.23826638  0.46060673  0.63384037  0.75398359  0.83332752  0.88678266\n",
      "  0.92152788  0.94470168  0.96033112  0.97061271]\n",
      "()\n",
      "test cold user\n",
      "[ 0.54553306  0.67512456  0.75773014  0.81699375  0.86114808  0.89466813\n",
      "  0.92066067  0.94116702  0.95610117  0.96699267]\n",
      "[ 0.54652435  0.67637865  0.75882391  0.81771064  0.86201169  0.89518416\n",
      "  0.92084417  0.94130998  0.95601549  0.96692114]\n",
      "[ 0.55653052  0.68717842  0.76926372  0.82713807  0.86947125  0.90144853\n",
      "  0.9259632   0.94504081  0.95891862  0.96929266]\n",
      "()\n",
      "test cold item\n",
      "[ 0.50707596  0.6656109   0.75284006  0.8099204   0.84818354  0.87657278\n",
      "  0.89739704  0.91296703  0.92510887  0.93596496]\n",
      "[ 0.50933396  0.66704784  0.75334558  0.81032999  0.84887929  0.87725017\n",
      "  0.89779317  0.91337293  0.92534461  0.93613338]\n",
      "[ 0.50768217  0.66564233  0.75257215  0.81005713  0.84841701  0.87732821\n",
      "  0.89785089  0.91339695  0.92534333  0.93623699]\n",
      "()\n",
      "----------------------------------------\n",
      "../model/dropout/exp4/model_4.h5\n",
      "train\n",
      "[ 0.28364311  0.31346394  0.33476789  0.35305822  0.37259805  0.39210482\n",
      "  0.41123072  0.4314715   0.45152538  0.47069288]\n",
      "[ 0.31106296  0.35011179  0.38146012  0.40964138  0.4366865   0.46233263\n",
      "  0.48666695  0.51054204  0.53342427  0.55493316]\n",
      "[ 0.28794296  0.32211095  0.34705634  0.36840447  0.39067238  0.41237591\n",
      "  0.43312841  0.45463949  0.47569505  0.49555379]\n",
      "()\n",
      "test warm\n",
      "[ 0.20308907  0.42522066  0.60624521  0.73538522  0.82041826  0.8782355\n",
      "  0.91566143  0.94078705  0.95768968  0.96857275]\n",
      "[ 0.26710343  0.49271289  0.65882621  0.77231052  0.84637798  0.89566094\n",
      "  0.92805651  0.94954364  0.96388396  0.97326312]\n",
      "[ 0.23616116  0.45793307  0.63189579  0.75294195  0.83213687  0.88595916\n",
      "  0.92097574  0.94446738  0.96012257  0.97048703]\n",
      "()\n",
      "test cold user\n",
      "[ 0.54584747  0.67540158  0.7577794   0.81729758  0.86129994  0.89479197\n",
      "  0.92070467  0.94114265  0.95603794  0.96701228]\n",
      "[ 0.54652435  0.67637865  0.75882391  0.81771064  0.86201169  0.89518416\n",
      "  0.92084417  0.94130998  0.95601549  0.96692114]\n",
      "[ 0.55668509  0.68727553  0.76901065  0.82671448  0.86910622  0.90095267\n",
      "  0.92550761  0.94478717  0.95874361  0.96915463]\n",
      "()\n",
      "test cold item\n",
      "[ 0.50690162  0.66526543  0.75245327  0.80936439  0.84818188  0.87674895\n",
      "  0.89759452  0.91316273  0.92525519  0.93606014]\n",
      "[ 0.50933396  0.66704784  0.75334558  0.81032999  0.84887929  0.87725017\n",
      "  0.89779317  0.91337293  0.92534461  0.93613338]\n",
      "[ 0.50760567  0.66562035  0.75298323  0.80998711  0.84850297  0.87668765\n",
      "  0.89738183  0.91297477  0.92514175  0.93605853]\n",
      "()\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Unable to open file (unable to open file: name = '../model/dropout/exp4/model_5.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0c4fd29cf2a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../model/dropout/exp4/model_%d.h5'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdropout_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   2656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to open file (unable to open file: name = '../model/dropout/exp4/model_5.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "sub_timer.start('evaluation of dropout net')\n",
    "for model_num in range(6):\n",
    "    model_path = '../model/dropout/exp4/model_%d.h5' % model_num\n",
    "    dropout_net.model.load_weights(model_path)\n",
    "    print('-'*40)\n",
    "    print(model_path)\n",
    "    user_content = generate_user_content(np.arange(num_user))\n",
    "    item_content = generate_item_content(np.arange(num_item))\n",
    "    dropout_user_all = dropout_net.user_model.predict([u_pref_scaled] + user_content)\n",
    "    dropout_item_all = dropout_net.item_model.predict([v_pref_scaled] + item_content)\n",
    "\n",
    "    klist = list(range(5, 51, 5))\n",
    "    print('train')\n",
    "    print(recall_random(klist, data_train))\n",
    "    print(recall_score_model(klist, data_train, v_user_all, v_item_all))\n",
    "    print(recall_score_model(klist, data_train, dropout_user_all, dropout_item_all))\n",
    "    print()\n",
    "\n",
    "    print('test warm')\n",
    "    print(recall_random(klist, data_test_warm))\n",
    "    print(recall_score_model(klist, data_test_warm, v_user_all, v_item_all))\n",
    "    print(recall_score_model(klist, data_test_warm, dropout_user_all, dropout_item_all))\n",
    "    print()\n",
    "    \n",
    "    print('test cold user')\n",
    "    print(recall_random(klist, data_test_cold_user))\n",
    "    print(recall_score_model(klist, data_test_cold_user, v_user_all, v_item_all))\n",
    "    print(recall_score_model(klist, data_test_cold_user, dropout_user_all, dropout_item_all))\n",
    "    print()\n",
    "\n",
    "    print('test cold item')\n",
    "    print(recall_random(klist, data_test_cold_item))\n",
    "    print(recall_score_model(klist, data_test_cold_item, v_user_all, v_item_all))\n",
    "    print(recall_score_model(klist, data_test_cold_item, dropout_user_all, dropout_item_all))\n",
    "    print()\n",
    "sub_timer.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
